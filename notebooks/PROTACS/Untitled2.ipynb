{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import Bio.PDB\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import glob\n",
    "import statistics\n",
    "import collections\n",
    "from scipy.spatial import distance\n",
    "from biopandas.pdb import PandasPdb\n",
    "\n",
    "parser = Bio.PDB.PDBParser(QUIET=True)\n",
    "\n",
    "####os.chdir('/groups/cherkasvgrp/share/progressive_docking/pd_python_pose/protacs/test_benchmark_protac_models')\n",
    "# here you input the desired ligase (FIRST) followed by the protein of protac target (SECOND)\n",
    "# both should be ligand bound \n",
    "# this is ran after HDOCK docking job\n",
    "# example of use is: python benchmarking_protacs_2.py 5t35_vhl 5t35_brd4\n",
    "\n",
    "pdb1_docked= str(sys.argv[1])\n",
    "pdb2_docked= str(sys.argv[2])\n",
    "model_0='model_1.pdb'\n",
    "\n",
    "# parsing ligand files that were dissected from the original ligase and protein of protac target (bash script)\n",
    "#pdb1_docked_splitted=str(pdb1_docked.split('.')[0])\n",
    "#pdb2_docked_splitted=str(pdb2_docked.split('.')[0])\n",
    "\n",
    "#pdb1_docked_splitted_csv=str(pdb1_docked_splitted.split('_')[3])\n",
    "#pdb2_docked_splitted_csv=str(pdb2_docked_splitted.split('_')[0])\n",
    "def parse_pdb_structure (pdb):\n",
    "    return(parser.get_structure(str(pdb.rsplit( \".\", 1 )[ 0 ]) , pdb))\n",
    " \n",
    "def combine_dicts(func, *dicts):\n",
    "    default = collections.defaultdict(set)\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            default[k].add(v)\n",
    "    return {k: func(v) for k, v in default.items()}\n",
    "\n",
    "# here we try to find the HDOCK model with the least distance between those two residues: ligase and POI\n",
    "def find_best_protac_model (ligand_coor1):\n",
    "    print('calculating best model which matches the least corresponding distance between those two residues ...') \n",
    " \n",
    "    if ligand_coor1.size == 0:\n",
    "        ppdb = PandasPdb().read_pdb(f'ligand_{pdb1_docked})\n",
    "        ligand_coor1=ppdb.df['HETATM'].iloc[:,11:14].to_numpy()\n",
    "    \n",
    "    avg_dis_dicts_models=[]\n",
    "    for filename in glob.iglob('ligand_model_*.pdb'):\n",
    "        ppdb = PandasPdb().read_pdb(filename)\n",
    "        ligand_coor2=ppdb.df['HETATM'].iloc[:,11:14].to_numpy()\n",
    "\n",
    "        close_atoms_ref=ligand_coor1\n",
    "        close_atoms_comp=ligand_coor2\n",
    "        \n",
    "        min_dis_dicts_models=[]\n",
    "\n",
    "        for i in close_atoms_ref:\n",
    "            min_dis_dicts_models.append({str(filename):float(min(np.linalg.norm(i - j) for j in close_atoms_comp))})\n",
    "            #print(f'{i} has minimum distance of {min(np.linalg.norm(i - j) for j in close_atoms_comp)} for model {filename}')\n",
    "        avg_dis_dicts_models.append(combine_dicts(statistics.mean, *min_dis_dicts_models))\n",
    "        \n",
    "    avg_dis_dicts_models_dics={k: v for d in avg_dis_dicts_models for k, v in d.items()}\n",
    "    best_model_1=min(avg_dis_dicts_models_dics, key=avg_dis_dicts_models_dics.get)\n",
    "    \n",
    "    top_models=[]\n",
    "    avg_dis_dicts_models_dics_updated ={}\n",
    "    top_models.append(best_model_1)\n",
    "    avg_dis_dicts_models_dics_updated = {key:val for key, val in avg_dis_dicts_models_dics.items()}\n",
    "    for i in range (19):\n",
    "        avg_dis_dicts_models_dics_updated = {key:val for key, val in avg_dis_dicts_models_dics_updated.items() if key != str(top_models[i])}\n",
    "        best_model_n=min(avg_dis_dicts_models_dics_updated, key=avg_dis_dicts_models_dics_updated.get)\n",
    "        top_models.append(best_model_n)\n",
    "        \n",
    "    return(top_models)\n",
    "\n",
    "def get_energy_difference (model):\n",
    "    \n",
    "    FILENAME = model\n",
    "    TARGET = \"Score:\"\n",
    "    score=float()\n",
    "\n",
    "    with open(FILENAME) as f:\n",
    "        value = None\n",
    "        start_seen = False\n",
    "        for line in f:\n",
    "            if TARGET in line:\n",
    "                _,value = line.split(':  ')\n",
    "                break\n",
    "\n",
    "    if value is not None:\n",
    "        score=value\n",
    "        \n",
    "    return (score)\n",
    "######################################################################################################\n",
    "#APPLYING\n",
    "\n",
    "\n",
    "ligase_attach_coordinates=get_ligase_ligand_info (pdb1_docked)\n",
    "\n",
    "top_models= find_best_protac_model(ligase_attach_coordinates)\n",
    "\n",
    "\n",
    "\n",
    "print(f'-> your best model is in {top_models[0]}')\n",
    "print(f'-> your second best model is in {top_models[1]}')\n",
    "print(f'-> your third best model is in {top_models[2]}')\n",
    "\n",
    "first_model_energy=get_energy_difference(str(model_0))\n",
    "energy_protac_all=[]\n",
    "for i in range (20):\n",
    "    protac_energy=get_energy_difference(str('_'.join(top_models[i].split('_')[1:])))\n",
    "    energy_protac_all.append(protac_energy)\n",
    "                                                          \n",
    "                                                                    \n",
    "print(f' Hdock predicted a score of {first_model_energy}: for the finest predicted pose')\n",
    "print(f' Whereas Hdock predicted a score of {energy_protac_all[0]}: for your best predicted protac model')\n",
    "energy_sacrificed= float(first_model_energy) - float(energy_protac_all[0])\n",
    "print(' The difference for energy sacrificed is {:.2f}'.format(energy_sacrificed))\n",
    "\n",
    "dir_name=f'{pdb1_docked}_{pdb2_docked}_results'\n",
    "\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "else:\n",
    "    #shutil.rmtree(dir_name)           # Removes all the subdirectories!\n",
    "    print('path ealready exists')\n",
    "\n",
    "for i in range(20):\n",
    "    shutil.copy(str(top_models[i]), dir_name)\n",
    "\n",
    "                                                                    \n",
    "BEs = [float(energy_protac_all[0]), float(energy_protac_all[1]), float(energy_protac_all[2]), float(energy_protac_all[3]),float(energy_protac_all[4]),float(energy_protac_all[5]), float(energy_protac_all[6]),float(energy_protac_all[7]),float(energy_protac_all[8]),float(energy_protac_all[9]),float(energy_protac_all[10]),float(energy_protac_all[11]),float(energy_protac_all[12]),float(energy_protac_all[13]),float(energy_protac_all[14]),float(energy_protac_all[15]),float(energy_protac_all[16]),float(energy_protac_all[17]),float(energy_protac_all[18]),float(energy_protac_all[19])]\n",
    "#models=[top_models[0], top_models[1], top_models[2], top_models[3],top_models[4], top_models[5],top_models[6], top_models[7], top_models[8], top_models[9],top_models[10],top_models[11],top_models[12],top_models[13],top_models[14],top_models[15],top_models[16],top_models[17],top_models[18],top_models[19]]\n",
    "models_modified=[str('_'.join(i.split('_')[1:])) for i in top_models]\n",
    "\n",
    "if str(pdb1_docked.split('.')[0].split('_')[3]) == 'UBR1':\n",
    "    identify='Ubr1'\n",
    "elif str(pdb1_docked.split('.')[0].split('_')[3]) == 'IAP':\n",
    "    identify='IAP'\n",
    "elif str(pdb1_docked.split('.')[0].split('_')[3]) == 'MDM2':\n",
    "    identify='Mdm2'\n",
    "elif str(pdb1_docked.split('.')[0].split('_')[3]) == 'CRBN':\n",
    "    identify='Cereblon'\n",
    "elif str(pdb1_docked.split('.')[0].split('_')[3]) == 'RNF114':\n",
    "    identify='RNF144'\n",
    "elif str(pdb1_docked.split('.')[0].split('_')[3]) == 'RNF144':\n",
    "    identify='RNF144'\n",
    "elif str(pdb1_docked.split('.')[0].split('_')[3]) == 'RNF4':\n",
    "    identify='RNF4'\n",
    "elif str(pdb1_docked.split('.')[0].split('_')[3]) == 'VHL':\n",
    "    identify='VHL'\n",
    "else:\n",
    "    print('None of the recognized E3 Binder is in your directory')\n",
    "    \n",
    "identifier=f'{identify}_{pdb2_docked.upper()}'\n",
    "\n",
    "for be in range(20):\n",
    "    data=[[str(pdb1_docked),str(pdb2_docked).upper(),BEs[be],models_modified[be],str(identifier)]]\n",
    "    df = pd.DataFrame(data, columns = ['Ligase', 'POI', 'be_auto', 'model_name', 'identifier'])\n",
    "    #df['be_auto']=BEs[be]\n",
    "    #df['mode_name']=models_modified[be]\n",
    "    #df['Ligase']=str(pdb1_docked)\n",
    "    #df['POI']=str(pdb2_docked).upper()\n",
    "    #df['identifier']=str(identifier)\n",
    "    df.to_csv(f'output_{be}.csv', index=False, header=False)\n",
    "    shutil.copy(f'output_{be}.csv', dir_name)\n",
    "\n",
    "#df.to_csv('output.csv', index=False)\n",
    "#shutil.copy('output.csv', dir_name)\n",
    "\n",
    "#for file in glob.glob('model_*pdb'):\n",
    "#    shutil.copy(file, dir_name)\n",
    "\n",
    "print(f'Done {pdb1_docked} & {pdb2_docked} ! All data written to output.csv in directory {dir_name}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import Bio.PDB\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import glob\n",
    "import statistics\n",
    "import collections\n",
    "from scipy.spatial import distance\n",
    "from biopandas.pdb import PandasPdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Bio.PDB.PDBParser(QUIET=True)\n",
    "\n",
    "pdb_docked= '5t35_brd4.pdb'   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_docked_splitted=str(pdb1_docked.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     A  \\\n",
      "0    [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "1    [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "2    [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "3    [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "4    [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "..                                                 ...   \n",
      "880  [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "881  [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "882  [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "883  [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "884  [23.097666666666665, -33.67418518518519, -14.6...   \n",
      "\n",
      "                              B   distance  \n",
      "0     [27.034, -69.694, -4.273]  37.680150  \n",
      "1      [27.48, -69.167, -5.601]  36.879843  \n",
      "2      [26.73, -67.889, -5.968]  35.476005  \n",
      "3     [27.351, -66.865, -6.258]  34.489010  \n",
      "4     [27.293, -70.219, -6.699]  37.626085  \n",
      "..                          ...        ...  \n",
      "880  [30.988, -68.843, -10.521]  36.274372  \n",
      "881  [31.725, -66.226, -12.588]  33.736384  \n",
      "882  [32.854, -66.595, -13.531]  34.353053  \n",
      "883  [33.236, -67.784, -13.579]  35.599580  \n",
      "884  [33.364, -65.692, -14.228]  33.625655  \n",
      "\n",
      "[885 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "ppdb = PandasPdb().read_pdb(pdb_docked)\n",
    "lig_x_coord,lig_y_coord,lig_z_coord= statistics.mean(list(ppdb.df['HETATM'].x_coord)), statistics.mean(list(ppdb.df['HETATM'].y_coord)), statistics.mean(list(ppdb.df['HETATM'].z_coord))\n",
    "ligand_coordinates_avg=[[lig_x_coord,lig_y_coord,lig_z_coord]]\n",
    "\n",
    "protein_coord=[]\n",
    "for i in range(len(ppdb.df['ATOM'])):\n",
    "    protein_coord.append([ppdb.df['ATOM'].x_coord[i], ppdb.df['ATOM'].y_coord[i], ppdb.df['ATOM'].z_coord[i]])\n",
    "\n",
    "def get_minimum_residue_distance (avg_ligand_coor, rec_coors):\n",
    "    dis_df = pd.DataFrame(columns=[\"A\", \"B\", \"distance\"])\n",
    "\n",
    "    for pair in product(avg_ligand_coor, rec_coors):\n",
    "        x, y = pair[0], pair[1]\n",
    "\n",
    "        dist = distance.euclidean(x, y)\n",
    "        dis_df = dis_df.append(\n",
    "            {'A': x, 'B': y, 'distance': dist}, ignore_index=True\n",
    "        )\n",
    "    print(dis_df)\n",
    "    the_minimum_index=dis_df.index[dis_df.distance == dis_df.distance.min()]\n",
    "    return(the_minimum_index.tolist()[0])\n",
    "\n",
    "most_minimum_dist_residue_index=get_minimum_residue_distance (ligand_coordinates_avg, protein_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdb_structure (pdb):\n",
    "    return(parser.get_structure(str(pdb.rsplit( \".\", 1 )[ 0 ]) , pdb))\n",
    "\n",
    "def what_chain_is_poi (structure):\n",
    "    chains=[]\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            chains.append(chain)\n",
    "    chain_id=int()\n",
    "    for i in range(len(chains)):\n",
    "        residues_list=[]\n",
    "        for idx, residue in enumerate(chains[i]):\n",
    "            residues_list.append(residue)\n",
    "        if len(residues_list)>=30:\n",
    "            chain_id=i\n",
    "            break\n",
    "        else:\n",
    "            print(f'poi not chain {i+2} ??')\n",
    "            continue\n",
    "    return(chain_id)\n",
    "\n",
    "chain_id=what_chain_is_poi(parse_pdb_structure(pdb_docked))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VAL439'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_residue_name=ppdb.df['ATOM'].iloc[most_minimum_dist_residue_index]['residue_name']\n",
    "target_residue_number=ppdb.df['ATOM'].iloc[most_minimum_dist_residue_index]['residue_number']\n",
    "target_residue=f'{target_residue_name}{target_residue_number}'\n",
    "target_residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure=parse_pdb_structure(pdb_docked)\n",
    "chains=[]\n",
    "idx_model=int()\n",
    "for model in structure:\n",
    "    for chain in model:\n",
    "        chains.append(chain)\n",
    "\n",
    "    for idx, residue in enumerate(chains[0]):\n",
    "        if f'resseq={target_residue_number} ' in str(residue):\n",
    "            idx_model=idx\n",
    "idx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[400,\n",
       " 438,\n",
       " 439,\n",
       " 380,\n",
       " 389,\n",
       " 386,\n",
       " 376,\n",
       " 447,\n",
       " 394,\n",
       " 390,\n",
       " 435,\n",
       " 369,\n",
       " 399,\n",
       " 372,\n",
       " 381,\n",
       " 301,\n",
       " 377,\n",
       " 387,\n",
       " 449,\n",
       " 382,\n",
       " 448,\n",
       " 428,\n",
       " 373,\n",
       " 370,\n",
       " 424,\n",
       " 378,\n",
       " 379,\n",
       " 374,\n",
       " 375,\n",
       " 444,\n",
       " 440,\n",
       " 429,\n",
       " 425,\n",
       " 371,\n",
       " 433,\n",
       " 430,\n",
       " 436,\n",
       " 445,\n",
       " 432,\n",
       " 441,\n",
       " 385,\n",
       " 446,\n",
       " 426,\n",
       " 427,\n",
       " 384,\n",
       " 393,\n",
       " 422,\n",
       " 423,\n",
       " 364,\n",
       " 437,\n",
       " 434,\n",
       " 398,\n",
       " 431,\n",
       " 442,\n",
       " 443]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import Bio.PDB\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import glob\n",
    "import statistics\n",
    "import collections\n",
    "from scipy.spatial import distance\n",
    "from biopandas.pdb import PandasPdb\n",
    "\n",
    "parser = Bio.PDB.PDBParser(QUIET=True)\n",
    "\n",
    "pdb_docked= '5t35_brd4.pdb'   \n",
    "\n",
    "ppdb = PandasPdb().read_pdb(pdb_docked)\n",
    "lig_x_coord,lig_y_coord,lig_z_coord= statistics.mean(list(ppdb.df['HETATM'].x_coord)), statistics.mean(list(ppdb.df['HETATM'].y_coord)), statistics.mean(list(ppdb.df['HETATM'].z_coord))\n",
    "ligand_coordinates_avg=[[lig_x_coord,lig_y_coord,lig_z_coord]]\n",
    "\n",
    "protein_coord=[]\n",
    "for i in range(len(ppdb.df['ATOM'])):\n",
    "    protein_coord.append([ppdb.df['ATOM'].x_coord[i], ppdb.df['ATOM'].y_coord[i], ppdb.df['ATOM'].z_coord[i]])\n",
    "\n",
    "def get_minimum_residue_distance (avg_ligand_coor, rec_coors):\n",
    "    dis_df = pd.DataFrame(columns=[\"A\", \"B\", \"distance\"])\n",
    "\n",
    "    for pair in product(avg_ligand_coor, rec_coors):\n",
    "        x, y = pair[0], pair[1]\n",
    "\n",
    "        dist = distance.euclidean(x, y)\n",
    "        dis_df = dis_df.append(\n",
    "            {'A': x, 'B': y, 'distance': dist}, ignore_index=True\n",
    "        )\n",
    "    print(dis_df)\n",
    "    the_minimum_index=dis_df.index[dis_df.distance == dis_df.distance.min()]\n",
    "    return(the_minimum_index.tolist()[0])\n",
    "\n",
    "most_minimum_dist_residue_index=get_minimum_residue_distance (ligand_coordinates_avg, protein_coord)\n",
    "def parse_pdb_structure (pdb):\n",
    "    return(parser.get_structure(str(pdb.rsplit( \".\", 1 )[ 0 ]) , pdb))\n",
    "\n",
    "def what_chain_is_poi (structure):\n",
    "    chains=[]\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            chains.append(chain)\n",
    "    chain_id=int()\n",
    "    for i in range(len(chains)):\n",
    "        residues_list=[]\n",
    "        for idx, residue in enumerate(chains[i]):\n",
    "            residues_list.append(residue)\n",
    "        if len(residues_list)>=30:\n",
    "            chain_id=i\n",
    "            break\n",
    "        else:\n",
    "            print(f'poi not chain {i+2} ??')\n",
    "            continue\n",
    "    return(chain_id)\n",
    "\n",
    "chain_id=what_chain_is_poi(parse_pdb_structure(pdb_docked))\n",
    "\n",
    "target_residue_name=ppdb.df['ATOM'].iloc[most_minimum_dist_residue_index]['residue_name']\n",
    "target_residue_number=ppdb.df['ATOM'].iloc[most_minimum_dist_residue_index]['residue_number']\n",
    "target_residue=f'{target_residue_name}{target_residue_number}'\n",
    "\n",
    "structure=parse_pdb_structure(pdb_docked)\n",
    "chains=[]\n",
    "idx_model=int()\n",
    "for model in structure:\n",
    "    for chain in model:\n",
    "        chains.append(chain)\n",
    "\n",
    "    for idx, residue in enumerate(chains[0]):\n",
    "        if f'resseq={target_residue_number} ' in str(residue):\n",
    "            idx_model=idx\n",
    "            \n",
    "residues_ref = [r for r in structure.get_residues()]\n",
    "target_atom = residues_ref[idx_model]['CA']\n",
    "atoms = Bio.PDB.Selection.unfold_entities(structure, 'A')\n",
    "ns = Bio.PDB.NeighborSearch(atoms)\n",
    "close_residues = ns.search(target_atom.coord, 15 ,'R')\n",
    "# close_atoms=[coor.coord for coor in close_atoms]\n",
    "res_all=[close_residues[i].get_full_id()[3][1] for i in range(len(close_residues))]\n",
    "res_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_coor (structure):\n",
    "    \n",
    "    ppdb = PandasPdb().read_pdb(structure)\n",
    "    ligand_coor1=ppdb.df['HETATM'].iloc[:,11:14].to_numpy()\n",
    "    atom_rec_coors={k:v for k, v in atom_rec_coors.items() if v}\n",
    "    return (atom_rec_coors)\n",
    "\n",
    "#function \n",
    "\n",
    "get_rec_coor(pdb_docked)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import Bio.PDB\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import math as m\n",
    "import glob\n",
    "import statistics\n",
    "import collections\n",
    "from scipy.spatial import distance\n",
    "from biopandas.pdb import PandasPdb\n",
    "\n",
    "parser = Bio.PDB.PDBParser(QUIET=True)\n",
    "\n",
    "# here you input the desired ligase (FIRST) followed by the protein of protac target (SECOND)\n",
    "# both should be ligand bound \n",
    "# this is ran after HDOCK docking job\n",
    "pdb_docked= str(sys.argv[1])     \n",
    "\n",
    "pdb_ligand=''\n",
    "\n",
    "# parsing ligand files that were dissected from the original ligase and protein of protac target (bash script)\n",
    "pdb_docked_splitted=str(pdb1_docked.split('.')[0])\n",
    "\n",
    "# parsing function for any protein to prep for further manipulation of the PDB\n",
    "def parse_pdb_structure (pdb):\n",
    "    return(parser.get_structure(str(pdb.rsplit( \".\", 1 )[ 0 ]) , pdb))\n",
    "\n",
    "# here it gets the receptor X Y Z coordinates of its constituting atoms as a dictionary\n",
    "def get_rec_coor (structure):\n",
    "    \n",
    "    atom_rec_coors={k:v for k, v in atom_rec_coors.items() if v}\n",
    "    return (atom_rec_coors)\n",
    "\n",
    "# here we process the dictionary from last function into iterable list of corrdinates\n",
    "def get_processed_list_rec_coor (atom_rec_coors):\n",
    "    \n",
    "    list_of_atom_rec_coors=list(atom_rec_coors.values())\n",
    "    return(list((i[0] for i in list_of_atom_rec_coors)))\n",
    "\n",
    "# here we get the ligand's average coordinate - averages all X Y Z of ligand's atoms\n",
    "def avg_ligand_coor (structure_ligand):\n",
    "    ligand_coor=list()\n",
    "    for model in structure_ligand:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                for atom in residue:\n",
    "                    x,y,z = atom.get_coord()\n",
    "\n",
    "                    ligand_coor.append((x,y,z))\n",
    "    avg_ligand_coors=[[sum(x)/len(x) for x in zip(*ligand_coor)]]\n",
    "    return (ligand_coor,avg_ligand_coors)\n",
    "\n",
    "# here we attempt to calculate the least distance between ligand average coordinate and corresponding protein\n",
    "def get_minimum_residue_distance (avg_ligand_coor, processed_list_of_atom_rec_coors):\n",
    "    dis_df = pd.DataFrame(columns=[\"A\", \"B\", \"distance\"])\n",
    "\n",
    "    for pair in product(avg_ligand_coor, processed_list_of_atom_rec_coors):\n",
    "        x, y = pair[0], pair[1]\n",
    "\n",
    "        dist = m.dist(x, y)\n",
    "        dis_df = dis_df.append(\n",
    "            {'A': x, 'B': y, 'distance': dist}, ignore_index=True\n",
    "        )\n",
    "\n",
    "    the_minimum_index=dis_df.index[dis_df.distance == dis_df.distance.min()]\n",
    "    return(the_minimum_index.tolist()[0])\n",
    "\n",
    "# in case the POI contains more than one chain we need the chain that has the bound ligand (greater probability)\n",
    "def what_chain_is_poi (structure):\n",
    "    chains=[]\n",
    "    idx_hdock_model_1st=int()\n",
    "    idx_hdock_model_2nd=int()\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            chains.append(chain)\n",
    "    chain_id=int()\n",
    "    chains.pop(0)\n",
    "    for i in range(len(chains)):\n",
    "        residues_list=[]\n",
    "        for idx, residue in enumerate(chains[i]):\n",
    "            residues_list.append(residue)\n",
    "        if len(residues_list)>=30:\n",
    "            chain_id=i+1\n",
    "            break\n",
    "        else:\n",
    "            print(f'poi not chain {i+2} ??')\n",
    "            continue\n",
    "    return(chain_id)\n",
    "\n",
    "# here we get the index of that residue in an HDOCKed model\n",
    "def get_residue_index_in_hdock_model (atom_rec1_coors, atom_rec2_coors, most_minimum_dist_residue1_index, \n",
    "                                               most_minimum_dist_residue2_index, structure, chain_poi_id):\n",
    "\n",
    "    res1_num=list(atom_rec1_coors.items())[int(most_minimum_dist_residue1_index)][0].split('-')[1]\n",
    "    res2_num=list(atom_rec2_coors.items())[int(most_minimum_dist_residue2_index)][0].split('-')[1]\n",
    "    \n",
    "    print(f'closest residue to bound ligand in {pdb1_docked} is residue {res1_num}')\n",
    "    print(f'closest residue to bound ligand in {pdb2_docked} is residue {res2_num}')\n",
    "    \n",
    "    chains=[]\n",
    "    idx_hdock_model_1st=int()\n",
    "    idx_hdock_model_2nd=int()\n",
    "    for model in structure:\n",
    "        for chain in model:\n",
    "            chains.append(chain)\n",
    "            \n",
    "        for idx, residue in enumerate(chains[0]):\n",
    "            if f'resseq={res1_num} ' in str(residue):\n",
    "                idx_hdock_model_1st=idx\n",
    "        for idx, residue in enumerate(chains[chain_poi_id]):\n",
    "            if f'resseq={res2_num} ' in str(residue):\n",
    "                idx_hdock_model_2nd=idx \n",
    "    return idx_hdock_model_1st, idx_hdock_model_2nd\n",
    "\n",
    "# \n",
    "def combine_dicts(func, *dicts):\n",
    "    default = collections.defaultdict(set)\n",
    "    for d in dicts:\n",
    "        for k, v in d.items():\n",
    "            default[k].add(v)\n",
    "    return {k: func(v) for k, v in default.items()}\n",
    "\n",
    "# here we try to find the HDOCK model with the least distance between those two residues: ligase and POI\n",
    "def find_best_protac_model (residue_a, residue_b, chain_poi_id):\n",
    "    print('calculating best model which matches the least corresponding distance between those two residues ...')      \n",
    "    avg_dis_dicts_models=[]\n",
    "    for filename in glob.iglob('model_*.pdb'):\n",
    "\n",
    "        chains=list()\n",
    "        structure=parse_pdb_structure (str(filename))\n",
    "\n",
    "        for model in structure:\n",
    "            for chain in model:\n",
    "                chains.append(chain)\n",
    "\n",
    "        structure_of_reference = chains[0] # 'structures' may contain several chains\n",
    "        structure_of_comparison= chains[chain_poi_id]\n",
    "\n",
    "        residues_ref = [r for r in structure_of_reference.get_residues()]\n",
    "        residues_comp= [r for r in structure_of_comparison.get_residues()]\n",
    "\n",
    "        target_atom_a = residues_ref[residue_a]['CA']\n",
    "        target_atom_b = residues_comp[residue_b]['CA']\n",
    "\n",
    "        atoms_a  = Bio.PDB.Selection.unfold_entities(structure_of_reference, 'A')\n",
    "        ns = Bio.PDB.NeighborSearch(atoms_a)\n",
    "\n",
    "        close_atoms_ref = ns.search(target_atom_a.coord, 1)\n",
    "\n",
    "        atoms_b  = Bio.PDB.Selection.unfold_entities(structure_of_comparison, 'A')\n",
    "        ns = Bio.PDB.NeighborSearch(atoms_b)\n",
    "\n",
    "        close_atoms_comp = ns.search(target_atom_b.coord, 25)\n",
    "\n",
    "        close_atoms_ref=[coor.coord for coor in close_atoms_ref]\n",
    "        close_atoms_comp=[coor.coord for coor in close_atoms_comp]\n",
    "        \n",
    "        #close_atoms_comp_len = len(close_atoms_comp)\n",
    "        #middle_index = close_atoms_comp_len//2\n",
    "        #close_atoms_comp_optimized=close_atoms_comp[middle_index:] + close_atoms_comp[0]\n",
    "        \n",
    "        min_dis_dicts_models=[]\n",
    "        \n",
    "        for i in close_atoms_ref:\n",
    "            min_dis_dicts_models.append({str(filename):min(np.linalg.norm(i - j) for j in close_atoms_comp)})\n",
    "            #print(f'{i} has minimum distance of {min(np.linalg.norm(i - j) for j in close_atoms_comp)} for model {filename}')\n",
    "        avg_dis_dicts_models.append(combine_dicts(statistics.mean, *min_dis_dicts_models))\n",
    "        \n",
    "    avg_dis_dicts_models_dics={k: v for d in avg_dis_dicts_models for k, v in d.items()}\n",
    "    best_model_1=min(avg_dis_dicts_models_dics, key=avg_dis_dicts_models_dics.get)\n",
    "    avg_dis_dicts_models_dics_updated = {key:val for key, val in avg_dis_dicts_models_dics.items() if key != str(best_model_1)}\n",
    "    best_model_2=min(avg_dis_dicts_models_dics_updated, key=avg_dis_dicts_models_dics_updated.get)\n",
    "    avg_dis_dicts_models_dics_updated_2 = {key:val for key, val in avg_dis_dicts_models_dics_updated.items() if key != str(best_model_2)}\n",
    "    best_model_3=min(avg_dis_dicts_models_dics_updated_2, key=avg_dis_dicts_models_dics_updated_2.get)\n",
    "    \n",
    "    return(best_model_1, best_model_2, best_model_3)\n",
    "\n",
    "def get_energy_difference (model):\n",
    "    \n",
    "    FILENAME = model\n",
    "    TARGET = \"Score:\"\n",
    "    score=float()\n",
    "\n",
    "    with open(FILENAME) as f:\n",
    "        value = None\n",
    "        start_seen = False\n",
    "        for line in f:\n",
    "            if TARGET in line:\n",
    "                _,value = line.split(':  ')\n",
    "                break\n",
    "\n",
    "    if value is not None:\n",
    "        score=value\n",
    "        \n",
    "    return (score)\n",
    "######################################################################################################\n",
    "#APPLYING\n",
    "\n",
    "pdb1=parse_pdb_structure (pdb1_docked)\n",
    "pdb2=parse_pdb_structure (pdb2_docked)\n",
    "model=parse_pdb_structure (model_0)\n",
    "\n",
    "rec_coor_pdb1=get_rec_coor(pdb1)\n",
    "rec_coor_pdb2=get_rec_coor(pdb2)\n",
    "\n",
    "processed_rec_coor_pdb1=get_processed_list_rec_coor (rec_coor_pdb1)\n",
    "processed_rec_coor_pdb2=get_processed_list_rec_coor (rec_coor_pdb2)\n",
    "\n",
    "ligand1_coors,avg_ligand1_coor=avg_ligand_coor (parse_pdb_structure(f'{str(pdb1_docked.rsplit( \".\", 1 )[ 0 ])}_ligand.pdb'))\n",
    "ligand2_coors,avg_ligand2_coor=avg_ligand_coor (parse_pdb_structure(f'{str(pdb2_docked.rsplit( \".\", 1 )[ 0 ])}_ligand.pdb'))\n",
    "\n",
    "min_distance_index_residue_to_ligand1= get_minimum_residue_distance (ligand1_coor, processed_rec_coor_pdb1)\n",
    "min_distance_index_residue_to_ligand2= get_minimum_residue_distance (ligand2_coor, processed_rec_coor_pdb2)\n",
    "\n",
    "chain_poi_id=what_chain_is_poi (model)\n",
    "\n",
    "residue_a, residue_b= get_residue_index_in_hdock_model (rec_coor_pdb1,rec_coor_pdb2,\n",
    "                                              min_distance_index_residue_to_ligand1, \n",
    "                                              min_distance_index_residue_to_ligand2,\n",
    "                                              model, chain_poi_id)\n",
    "\n",
    "best_model, best_model_2, best_model_3 =find_best_protac_model(residue_a, residue_b, chain_poi_id)\n",
    "\n",
    "\n",
    "print(f'-> your best model is in {best_model}')\n",
    "print(f'-> your second best model is in {best_model_2}')\n",
    "print(f'-> your third best model is in {best_model_3}')\n",
    "\n",
    "first_model_energy=get_energy_difference(str(model_0))\n",
    "best_protac_energy=get_energy_difference(str(best_model))\n",
    "second_best_protac_energy=get_energy_difference(str(best_model_2))\n",
    "third_best_protac_energy=get_energy_difference(str(best_model_3))\n",
    "\n",
    "print(f' Hdock predicted a score of {first_model_energy}: for the finest predicted pose')\n",
    "print(f' Whereas Hdock predicted a score of {best_protac_energy}: for your best predicted protac model')\n",
    "energy_sacrificed= float(first_model_energy) - float(best_protac_energy)\n",
    "print(' The difference for energy sacrificed is {:.2f}'.format(energy_sacrificed))\n",
    "\n",
    "dir_name=f'{pdb1_docked_splitted}_{pdb2_docked_splitted}_results'\n",
    "\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "else:\n",
    "    #shutil.rmtree(dir_name)           # Removes all the subdirectories!\n",
    "    pass\n",
    "shutil.move(best_model, dir_name)\n",
    "shutil.move(best_model_2, dir_name)\n",
    "shutil.move(best_model_3, dir_name)\n",
    "\n",
    "data = [[pdb1_docked_splitted_csv, pdb2_docked_splitted_csv, float(best_protac_energy), float(second_best_protac_energy), float(third_best_protac_energy), float(first_model_energy), best_model, best_model_2, best_model_3]]\n",
    "\n",
    "        \n",
    "df = pd.DataFrame(data, columns = ['Ligase', 'POI', '1st best model', '2nd best model', \n",
    "                                   'Third best model', 'MODEL 0', 'Name model 1st', 'Name model 2nd', \n",
    "                                   'Name model 3rd'])\n",
    "\n",
    "df.to_csv('output.csv')\n",
    "shutil.move('output.csv', dir_name)\n",
    "\n",
    "for file in glob.glob('model_*pdb'):\n",
    "    shutil.copy(file, dir_name)\n",
    "\n",
    "print(f'Done {pdb1_docked} & {pdb2_docked} ! All data written to output.csv in directory {dir_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = [a.parent.parent.id + '-' + str(a.parent.id[1]) + '-' +  a.name for a in structure.get_atoms() \n",
    "    if a.parent.id[0] == ' ']\n",
    "\n",
    "    atom_rec_coors = {}\n",
    "    for atom in atoms:\n",
    "        atom_rec_coors[atom] = []\n",
    "        for model in structure:\n",
    "            atom_ = atom.split('-')\n",
    "            try:\n",
    "                coor = model[atom_[0]][int(atom_[1])][atom_[2]].coord\n",
    "                atom_rec_coors[atom].append(coor.tolist())\n",
    "            except:\n",
    "                print(f'Could not find coordinates for {str(structure)} at Atom {atom_}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
