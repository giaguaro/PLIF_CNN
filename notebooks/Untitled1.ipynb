{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d70db9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b37edcccf689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenbabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreparation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPDBComplex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexchange\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBindingSiteReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plip'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import openbabel\n",
    "import numpy as np\n",
    "from plip.structure.preparation import PDBComplex\n",
    "from plip.exchange.report import BindingSiteReport\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from biopandas.pdb import PandasPdb\n",
    "from Bio.PDB.SASA import ShrakeRupley\n",
    "from Bio.PDB import PDBParser\n",
    "import oddt\n",
    "from oddt import fingerprints\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class PLIF:\n",
    "    def __init__(self, PDB: str, MOL_SPLIT_START: int = 70, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(PLIF,self).__init__()\n",
    "        \n",
    "        self.MOL_SPLIT_START=MOL_SPLIT_START\n",
    "        self.pdb=PDB\n",
    "        self.records=['ATOM']\n",
    "        self.values=['HOH','CL','MG','ZN','MN','CA']\n",
    "        self.interaction_slices={\"hydrophobic\":[0,1,6,7,8,9,10],\n",
    "            \"hbond\":[0,1,7,11,13,15,16],\n",
    "            \"waterbridge\":[0,1,[6,7],11,13,16,17],\n",
    "            \"saltbridge\":[0,1,7,10,3,11,12],\n",
    "            \"pistacking\":[0,1,7,11,6,12,13],\n",
    "            \"pication\":[0,1,7,11,3,12,13],\n",
    "            \"halogen\":[0,1,7,10,12,14,15],\n",
    "            \"metal\":[0,1,11,8,6,17,16]} \n",
    "\n",
    "        self.column_names = ['RESNR', 'RESTYPE', 'DIST', 'LIG_IDX','PROT_IDX','FRAGMENT_ATOMS_COORDS', 'AA_COORDS']\n",
    "        self.path = os.getcwd()\n",
    "\n",
    "\n",
    "    def okToBreak(self, bond):\n",
    "        \"\"\"\n",
    "        Here we apply a bunch of rules to judge if the bond is OK to break.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bond :\n",
    "            RDkit MOL object\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Boolean :\n",
    "            OK or not to break.\n",
    "        \"\"\"\n",
    "        # See if the bond is in Ring (don't break that)\n",
    "        if bond.IsInRing():\n",
    "            return False\n",
    "        # We OK only single bonds to break\n",
    "        if bond.GetBondType() != Chem.rdchem.BondType.SINGLE:\n",
    "            return False\n",
    "\n",
    "        # Get the beginning atom of the bond\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        # Get the ending atom of the bond\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        # What kind of neighbors does these end and begenning atoms have? We need a family of no less than 5!\n",
    "        neighbor_end=list(end_atom.GetNeighbors())\n",
    "        neighbor_begin=list(begin_atom.GetNeighbors())\n",
    "        if (len(neighbor_end) + len(neighbor_begin)) <5:\n",
    "            return False\n",
    "        #for atm in neighbor_end:\n",
    "            #print(atm.GetAtomicNum())\n",
    "        #print(begin_atom.GetAtomicNum(), end_atom.GetAtomicNum(), MOL_SPLIT_START)\n",
    "        \n",
    "        # Now check if end or begenning atoms are in ring (we dont wanna bother those)\n",
    "        if not(begin_atom.IsInRing() or end_atom.IsInRing()):\n",
    "            return False\n",
    "        elif begin_atom.GetAtomicNum() >= self.MOL_SPLIT_START or \\\n",
    "                end_atom.GetAtomicNum() >= self.MOL_SPLIT_START:\n",
    "            return False\n",
    "        elif end_atom.GetAtomicNum() == 1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def undo_id_label (self, frag, split_id):\n",
    "        # I am trying to restore Hydrogens where the break happened\n",
    "        for i, atom in enumerate(frag.GetAtoms()):\n",
    "            if atom.GetAtomicNum() >= split_id:\n",
    "                atom.SetAtomicNum(1)\n",
    "\n",
    "        return frag\n",
    "\n",
    "    # Divide a molecule into fragments\n",
    "    def split_molecule(self, mol, pdb):\n",
    "\n",
    "        split_id = self.MOL_SPLIT_START\n",
    "\n",
    "        res = []\n",
    "        res_no_id=[]\n",
    "\n",
    "        to_check = [mol]\n",
    "        while len(to_check) > 0:\n",
    "            ms = self.spf(to_check.pop(), split_id)\n",
    "            if len(ms) == 1:\n",
    "                res += ms\n",
    "            else:\n",
    "                to_check += ms\n",
    "                split_id += 1\n",
    "        for frag in res:\n",
    "            res_no_id.append(self.undo_id_label(frag, self.MOL_SPLIT_START))\n",
    "\n",
    "        res_pdb_frags=[]\n",
    "\n",
    "        for idx, frag in enumerate(res_no_id):\n",
    "            w = Chem.PDBWriter(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "            w.write(frag)\n",
    "            w.close()\n",
    "            \n",
    "            unwanted_entries= ['CONECT', 'END']            \n",
    "            with open(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as oldfile, open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as newfile:\n",
    "                for line in oldfile:\n",
    "                    if not any(unwanted_entry in line for unwanted_entry in unwanted_entries):\n",
    "                        newfile.write(line)\n",
    "\n",
    "                    \n",
    "            data = data2 = \"\"\n",
    "\n",
    "            # Reading data from file1\n",
    "            with open(f\"ATOM_{pdb}.pdb\") as fp:\n",
    "                data = fp.read()\n",
    "\n",
    "            # Reading data from file2\n",
    "\n",
    "            with open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as fp:\n",
    "                data2 = fp.read()\n",
    "            \n",
    "            # Merging 2 files\n",
    "            # To add the data of file2\n",
    "            # from next line\n",
    "            #data += \"\\n\"\n",
    "            data += data2\n",
    "            \n",
    "            with open(f\"HOH_{pdb}.pdb\") as fp:\n",
    "                data3 = fp.read()\n",
    "            data += data3\n",
    "\n",
    "            with open (f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as fp:\n",
    "                fp.write(data)\n",
    "            res_pdb_frags.append(f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "        return res_pdb_frags #create_chain(res)\n",
    "\n",
    "\n",
    "    # Function for doing all the nitty gritty splitting work.\n",
    "    # loops over bonds until bonds get exhausted or bonds are ok to break, whichever comes first. If ok to break, then each\n",
    "    # fragment needs to be checked individually again through the loop\n",
    "    def spf(self, mol, split_id):\n",
    "\n",
    "        bonds = mol.GetBonds()\n",
    "        for i in range(len(bonds)):\n",
    "            if self.okToBreak(bonds[i]):\n",
    "                mol = Chem.FragmentOnBonds(mol, [i])\n",
    "                # Dummy atoms are always added last\n",
    "                n_at = mol.GetNumAtoms()\n",
    "                print('Split ID', split_id)\n",
    "                mol.GetAtomWithIdx(n_at-1).SetAtomicNum(split_id)\n",
    "                mol.GetAtomWithIdx(n_at-2).SetAtomicNum(split_id)\n",
    "                return Chem.rdmolops.GetMolFrags(mol, asMols=True)\n",
    "\n",
    "        # If the molecule could not been split, return original molecule\n",
    "        return [mol]\n",
    "    #get_fragments(fragment_mols)\n",
    "\n",
    "    def retreive_plip_interactions(self, pdb_file):\n",
    "        \"\"\"\n",
    "        Retreives the interactions from PLIP.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdb_file :\n",
    "            The PDB file of the complex. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict :\n",
    "            A dictionary of the binding sites and the interactions.\n",
    "        \"\"\"\n",
    "        protlig = PDBComplex()   #instantiate the loader from PLIP\n",
    "        protlig.load_pdb(pdb_file)   # load the pdb file\n",
    "        for ligand in protlig.ligands:\n",
    "            protlig.characterize_complex(ligand)   # find ligands and analyze interactions\n",
    "        sites = {}\n",
    "        # loop over binding sites\n",
    "        for key, site in sorted(protlig.interaction_sets.items()):\n",
    "            binding_site = BindingSiteReport(site)   # collect data about interactions\n",
    "            # tuples of *_features and *_info will be converted to pandas DataFrame\n",
    "            keys = (\n",
    "                \"hydrophobic\",\n",
    "                \"hbond\",\n",
    "                \"waterbridge\",\n",
    "                \"saltbridge\",\n",
    "                \"pistacking\",\n",
    "                \"pication\",\n",
    "                \"halogen\",\n",
    "                \"metal\"\n",
    "            )\n",
    "        # interactions is a dictionary which contains relevant information for each\n",
    "        # of the possible interactions: hydrophobic, hbond, etc. in the considered\n",
    "        # binding site. Each interaction contains a list with \n",
    "        # 1. the features of that interaction, e.g. for hydrophobic:\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "        # 2. information for each of these features, e.g. for hydrophobic\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "\n",
    "            interactions = {\n",
    "                k: [getattr(binding_site, k + \"_features\")] + getattr(binding_site, k + \"_info\")\n",
    "                for k in keys\n",
    "            }\n",
    "            sites[key] = interactions\n",
    "        return sites\n",
    "\n",
    "    def get_coords_prot(self, RESNR):\n",
    "        ppdb = PandasPdb()\n",
    "        ppdb.read_pdb(f\"{self.pdb.split('.')[0]}_protein.pdb\")\n",
    "        only_protein=ppdb.df['ATOM']\n",
    "        resnr_coords=[]\n",
    "        for i in RESNR:\n",
    "            resnr_coords.append(list(only_protein[only_protein['atom_number']==int(i)][['x_coord', 'y_coord', 'z_coord']].values[0]))\n",
    "        return resnr_coords\n",
    "    \n",
    "    ### the most slow function out of all this garbage code ###\n",
    "    def aa_descriptors_asa(self, fragment_idx, aa, coords, extra_feats):\n",
    "        p = PDBParser(QUIET=1)\n",
    "        structure = p.get_structure(self.pdb.split('.')[0], f\"ATOM_{self.pdb.split('.')[0]}_{fragment_idx}.pdb\")\n",
    "        sr = ShrakeRupley()\n",
    "        \n",
    "        sasa_res=[]\n",
    "        sasa_atom=[]\n",
    "\n",
    "        for a in aa: \n",
    "            for chain in structure[0]:\n",
    "                for res in chain:\n",
    "                    if f'={a} ' in str(res.__repr__()):\n",
    "                        sr.compute(structure[0], level=\"R\")\n",
    "                        sasa_res.append(round(res.sasa,2))\n",
    "                        sr.compute(structure[0], level=\"A\")\n",
    "                        for coor in coords:\n",
    "                            for atom in res:\n",
    "                                if [round(item) for item in atom.get_coord()] == [round(np.float32(item)) for item in coor]:\n",
    "                                    sasa_atom.append(round(atom.sasa,2))\n",
    "\n",
    "#                         #if all(v == 0.0 for v in sasas):\n",
    "                        if not sasa_atom:\n",
    "                            try:\n",
    "                                coords=self.get_coords_prot(extra_feats[0].split(',') if ',' in extra_feats[0] \\\n",
    "                                                               else extra_feats)\n",
    "                                for coor in coords:\n",
    "                                    for atom in res:\n",
    "                                        if [round(item) for item in atom.get_coord()] == [round(np.float32(item)) for item in coor]:\n",
    "                                            sasa_atom.append(round(atom.sasa,2))\n",
    "                            except Exception:\n",
    "                                print(f\"no SASA for AA idx {a}'s atom'\")\n",
    "                                \n",
    "                \n",
    "        return [sasa_atom], [sasa_res] , coords\n",
    "                \n",
    "    def interaction_df(self, split):\n",
    "\n",
    "        all_interactions_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        # We create the dictionary for the complex of interest:\n",
    "        for idx, s in enumerate(split):\n",
    "\n",
    "            pdb_id=s.split('.')[0]\n",
    "            raw=pdb_id.split('_')[1]\n",
    "            idx_frag=int(pdb_id.split('_')[2])\n",
    "            interactions_by_site = self.retreive_plip_interactions(f\"{pdb_id}.pdb\")\n",
    "\n",
    "            # Let’s see how many binding sites are detected:\n",
    "\n",
    "    #         print(\n",
    "    #             f\"Number of binding sites detected in {pdb_id} : \"\n",
    "    #             f\"{len(interactions_by_site)}\\n\"\n",
    "    #             f\"with {interactions_by_site.keys()}\"\n",
    "    #         )\n",
    "            # In this case, the first binding site containing ligand 03P will be further investigated.\n",
    "            index_of_selected_site = 0\n",
    "            selected_site = list(interactions_by_site.keys())[index_of_selected_site]\n",
    "            #print(selected_site)\n",
    "\n",
    "\n",
    "            valid_types = [\n",
    "                    \"hydrophobic\",\n",
    "                    \"hbond\",\n",
    "                    \"waterbridge\",\n",
    "                    \"saltbridge\",\n",
    "                    \"pistacking\",\n",
    "                    \"pication\",\n",
    "                    \"halogen\",\n",
    "                    \"metal\",\n",
    "                ]\n",
    "\n",
    "            for _type in valid_types:\n",
    "                output_df=self.create_df_from_binding_site(raw, interactions_by_site[selected_site], idx+self.MOL_SPLIT_START, selected_site,\n",
    "                                                      interactions_by_site,\n",
    "                                                      interaction_type=_type)\n",
    "                all_interactions_df=all_interactions_df.append(output_df)\n",
    "        all_interactions_df = all_interactions_df[all_interactions_df['RESNR'].notna()]\n",
    "        all_interactions_df.to_csv(f\"{self.path}/results_plifs/{raw}_plifs_and_properties.csv\", index=False)\n",
    "        return all_interactions_df\n",
    "\n",
    "\n",
    "    # We can construct a pandas.DataFrame for a binding site and particular interaction type.\n",
    "\n",
    "    def create_df_from_binding_site(self, raw, selected_site_interactions, fragment_idx, selected_site, \n",
    "                                    interactions_by_site, interaction_type=\"hbond\"):\n",
    "        \"\"\"\n",
    "        Creates a data frame from a binding site and interaction type.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selected_site_interactions : dict\n",
    "            Precalculated interactions from PLIP for the selected site\n",
    "        interaction_type : str\n",
    "            The interaction type of interest (default set to hydrogen bonding).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame :\n",
    "            DataFrame with information retreived from PLIP.\n",
    "        \"\"\"\n",
    "        # check if interaction type is valid:\n",
    "        valid_types = [\n",
    "            \"hydrophobic\",\n",
    "            \"hbond\",\n",
    "            \"waterbridge\",\n",
    "            \"saltbridge\",\n",
    "            \"pistacking\",\n",
    "            \"pication\",\n",
    "            \"halogen\",\n",
    "            \"metal\",\n",
    "        ]\n",
    "\n",
    "\n",
    "        if interaction_type not in valid_types:\n",
    "            print(\"!!! Wrong interaction type specified. Hbond is chosen by default !!! \\n\")\n",
    "            interaction_type = \"hbond\"\n",
    "\n",
    "        def interaction_values(n):\n",
    "            try:\n",
    "                interactions=interactions_by_site[selected_site][interaction_type]\n",
    "                if type(n) is list:\n",
    "                    return [interactions[1:][x][i] for x in \n",
    "                        range(len(interactions[1:])) for i in n]\n",
    "                else:\n",
    "                    return [interactions[1:][x][n] for x in \n",
    "                        range(len(interactions[1:]))]\n",
    "            except Exception:\n",
    "                return None\n",
    "            \n",
    "        if interactions_by_site[selected_site][interaction_type][1:]:\n",
    "            #print(list(map(interaction_values, self.interaction_slices[interaction_type])), self.column_names)\n",
    "            selected_feats=list(map(interaction_values, self.interaction_slices[interaction_type]))\n",
    "            #print(selected_feats)\n",
    "            try: \n",
    "                if int(selected_feats[4])>int(selected_feats[3]):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3]  \n",
    "            except: \n",
    "                if int(any(selected_feats[4]))>int(any(selected_feats[3])):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3] \n",
    "            df = pd.DataFrame(\n",
    "                # data is stored AFTER the columns names\n",
    "                [selected_feats],\n",
    "                # column names are always the first element - we skipped that in the above - we are gonna use that for naming the df\n",
    "                columns = self.column_names\n",
    "            )\n",
    "\n",
    "            df[\"INTERACTION_TYPE\"]=interaction_type\n",
    "            df[\"ATOM_SASA\"], df[\"AA_SASA\"], extra_coords = self.aa_descriptors_asa(fragment_idx,selected_feats[0],\n",
    "                                                                  [list(x) for x in selected_feats[6]],\n",
    "                                                                 selected_feats[4]) \n",
    "                                                                  #df[\"AA_COORDS\"].values[0])\n",
    "            df[\"AA_COORDS\"]=[extra_coords]\n",
    "                #[self.get_coords_prot(selected_feats[4].split(','))]\n",
    "            df[\"FRAGMENT_ATOMS_COORDS\"]=[selected_feats[5]]\n",
    "                            #[self.get_coords_lig(selected_feats[3].split(','))]    \n",
    "            df['FRAGMENT_ID']=fragment_idx\n",
    "\n",
    "            # ideally we would like to exclude waters from further processing. Threrfore let us reduce any waterbridge \n",
    "            # interaction to the eucladean distance in order to omit water\n",
    "            \n",
    "            if interaction_type == \"waterbridge\":\n",
    "                df['DIST']=[[np.linalg.norm(x) for x in df['DIST'].to_numpy()]]\n",
    "                \n",
    "            # also deal with one distance value and two coords, this is common in saltbridge interactions:\n",
    "            if len(extra_coords) == len(selected_feats[2])*2:\n",
    "                df['DIST']=[selected_feats[2] + selected_feats[2]]\n",
    "                \n",
    "        else:\n",
    "\n",
    "            df= pd.DataFrame({'RESNR':[None], 'RESTYPE':[None], 'DIST':[None], 'LIG_IDX':[None],'PROT_IDX':[None],\n",
    "                        'INTERACTION_TYPE':[interaction_type], \"AA_COORDS\": [None], \"FRAGMENT_ATOMS_COORDS\":[None],\n",
    "                        \"ATOM_SASA\":[None],\"AA_SASA\":[None],\n",
    "                              'FRAGMENT_ID':[str(fragment_idx)]})\n",
    "\n",
    "\n",
    "\n",
    "        return df\n",
    "    def pdb_2_sdf(self, pdb):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"pdb\", \"sdf\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, pdb)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "\n",
    "\n",
    "        obConversion.WriteFile(mol, f\"{pdb.split('.')[0]}.sdf\")\n",
    "        return f\"{pdb.split('.')[0]}.sdf\"\n",
    "    \n",
    "    def sdf_2_pdb(self, sdf):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"sdf\", \"pdb\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, sdf)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "        obConversion.WriteFile(mol, f\"{sdf.split('.')[0]}.pdb\")\n",
    "        return f\"HETATM_{sdf.split('.')[0]}.pdb\"\n",
    "\n",
    "    def save_bpdb(self, pdb,ppdb, record):  \n",
    "        ppdb.to_pdb(path=f\"{record}_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                    records=[record],\n",
    "                    gz=False, \n",
    "                    append_newline=True)\n",
    "\n",
    "    def get_HOH_pdb(self, pdb):\n",
    "        ppdb = PandasPdb() \n",
    "        ppdb.read_pdb(pdb) \n",
    "        ppdb.df['HETATM']=ppdb.df['HETATM'].loc[ppdb.df['HETATM']['residue_name'].isin(self.values)]\n",
    "        ppdb.to_pdb(path=f\"HOH_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                records=['HETATM'],\n",
    "                gz=False, \n",
    "                append_newline=True)\n",
    "\n",
    "    def keep_relevant_hetatm(self, pdb):\n",
    "#         pdb = self.pdb\n",
    "        ppdb = PandasPdb() \n",
    "        ppdb.read_pdb(pdb)    \n",
    "\n",
    "        ##ppdb.df['HETATM']=ppdb.df['HETATM'][ppdb.df['HETATM'].residue_name == self.getLigandName(str(pdb).split('.')[0])]  \n",
    "        for c in self.records:\n",
    "            self.save_bpdb(pdb,ppdb, c)\n",
    "        self.get_HOH_pdb(pdb)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def fragment_and_plif(self):\n",
    "        path = os.getcwd()\n",
    "        if not os.path.exists('results_plifs'):\n",
    "            os.mkdir(f'{path}/results_plifs')\n",
    "         \n",
    "        raw=str(self.pdb).split('.')[0]\n",
    "        self.keep_relevant_hetatm(f'{raw}_protein.pdb')\n",
    "        self.sdf_2_pdb(f'{raw}_ligand.sdf')\n",
    "        fragment_mols = Chem.SDMolSupplier(str(f'{raw}_ligand.sdf'), removeHs=True, sanitize=False)\n",
    "        try: fragment_mols = Chem.RemoveHs(fragment_mols[0])\n",
    "        except: fragment_mols = AllChem.MolFromPDBFile(f'{raw}_ligand.pdb')\n",
    "        output_df = self.interaction_df(self.split_molecule(fragment_mols,raw))\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "#         for filePath in fileList:\n",
    "#             try:\n",
    "#                 os.remove(filePath)\n",
    "#             except:\n",
    "#                 print(\"Error while deleting file : \", filePath)\n",
    "#         os.chdir(f'{path}')\n",
    "        \n",
    "        return output_df.groupby('FRAGMENT_ID')['AA_COORDS', 'FRAGMENT_ATOMS_COORDS','INTERACTION_TYPE','DIST','ATOM_SASA','AA_SASA'].agg(list)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    df = PLIF(PDB = '5te0.pdb').fragment_and_plif()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
