{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc1f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from openbabel import pybel\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# 45次实验分别进行10倍交叉验证，取平均\n",
    "\n",
    "#Converts the protein-ligand complexes into 4D tensor. \n",
    "class Feature_extractor():\n",
    "    def __init__(self):\n",
    "        self.atom_codes = {}\n",
    "        #'others' includs metal atoms and B atom. There are no B atoms on training and test sets. \n",
    "        # 55 to 65 will be reserved to PLIF features as follows:\n",
    "        # 55: hydrophobic\n",
    "        # 56: hbond\n",
    "        # 57: waterbridge\n",
    "        # 58: saltbridge\n",
    "        # 59: pistacking\n",
    "        # 60: pication\n",
    "        # 61: halogen\n",
    "        # 62: metal\n",
    "        # 63: Distances \n",
    "        # 64: SASA ATOM\n",
    "        # 65: SASA AA\n",
    "        \n",
    "        # others = ([3,4,5,11,12,13]+list(range(19,32))+list(range(37,51))+list(range(55,84)))\n",
    "        plif_specs=list(range(55,66))\n",
    "        #C and N atoms can be hybridized in three ways and S atom can be hybridized in two ways here. \n",
    "        #Hydrogen atom is also considered for feature extraction. I think phosphor atom has 3 or 5 as hyb states but \n",
    "        # in biological system its usually the same recurrent phosphate even in most small molecules so safe to assume one\n",
    "        # hybridization state for this purpose. \n",
    "        atom_types = [1,(6,1),(6,2),(6,3),(7,1),(7,2),(7,3),8,15,(16,2),(16,3),\n",
    "                      34,9,17,35,53,11,12,13,14,5,19,20,25,29,28,30]+plif_specs\n",
    "      \n",
    "        for i, j in enumerate(atom_types):\n",
    "            if type(j) is list:\n",
    "                for k in j:\n",
    "                    self.atom_codes[k] = i\n",
    "                \n",
    "            else:\n",
    "                self.atom_codes[j] = i              \n",
    "        \n",
    "        self.sum_atom_types = len(atom_types)\n",
    "        \n",
    "    #Onehot encoding of each atom. The atoms in protein or ligand are treated separately.\n",
    "    def encode(self, atomic_num, orig_coords, plifs, molprotein):\n",
    "        encoding = np.zeros(self.sum_atom_types*2)\n",
    "        if molprotein == 1:\n",
    "            encoding[self.atom_codes[atomic_num]] = 1.0\n",
    "            for coord, plif_feats in plifs.items():\n",
    "                if [round(item) for item in coord] == [round(item) for item in orig_coords]:\n",
    "                    encoding[self.atom_codes[55]] = 1.0 if plifs[coord][0] == 'hydrophobic' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[56]] = 1.0 if plifs[coord][0] == 'hbond' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[57]] = 1.0 if plifs[coord][0] == 'waterbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[58]] = 1.0 if plifs[coord][0] == 'saltbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[59]] = 1.0 if plifs[coord][0] == 'pistacking' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[60]] = 1.0 if plifs[coord][0] == 'pication' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[61]] = 1.0 if plifs[coord][0] == 'halogen' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[62]] = 1.0 if plifs[coord][0] == 'metal' \\\n",
    "                    else 0.0\n",
    "                    \n",
    "                    encoding[self.atom_codes[63]] = plifs[coord][1]\n",
    "                    encoding[self.atom_codes[64]] = plifs[coord][2]\n",
    "                    encoding[self.atom_codes[65]] = plifs[coord][3]\n",
    "                \n",
    "        else:\n",
    "            encoding[self.sum_atom_types+self.atom_codes[atomic_num]] = 1.0\n",
    "            for coord, plif_feats in plifs.items():\n",
    "                if [round(item) for item in coord] == [round(item) for item in orig_coords]:\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[55]] = 1.0 if plifs[coord][0] == 'hydrophobic' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[56]] = 1.0 if plifs[coord][0] == 'hbond' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[57]] = 1.0 if plifs[coord][0] == 'waterbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[58]] = 1.0 if plifs[coord][0] == 'saltbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[59]] = 1.0 if plifs[coord][0] == 'pistacking' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[60]] = 1.0 if plifs[coord][0] == 'pication' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[61]] = 1.0 if plifs[coord][0] == 'halogen' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[62]] = 1.0 if plifs[coord][0] == 'metal' \\\n",
    "                    else 0.0\n",
    "                    \n",
    "                    encoding[self.sum_atom_types+self.atom_codes[63]] = plifs[coord][1]\n",
    "                    \n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    #Get atom coords and atom features from the complexes.   \n",
    "    def get_features(self, molecule, plifs, molprotein):\n",
    "        coords = []\n",
    "        features = []\n",
    "            \n",
    "        for atom in molecule:\n",
    "            coords.append(atom.coords)\n",
    "            if atom.atomicnum in [6,7,16]:\n",
    "                atomicnum = (atom.atomicnum,atom.hyb)\n",
    "                features.append(self.encode(atomicnum,atom.coords,plifs,molprotein))\n",
    "            else:\n",
    "                features.append(self.encode(atom.atomicnum,atom.coords,plifs,molprotein))\n",
    "        \n",
    "        coords = np.array(coords, dtype=np.float32)\n",
    "        features = np.array(features, dtype=np.float32)\n",
    "\n",
    "        return coords, features\n",
    "     \n",
    "    #Define the rotation matrixs of 3D stuctures.\n",
    "    def rotation_matrix(self, t, roller):\n",
    "        if roller==0:\n",
    "            return np.array([[1,0,0],[0,np.cos(t),np.sin(t)],[0,-np.sin(t),np.cos(t)]])\n",
    "        elif roller==1:\n",
    "            return np.array([[np.cos(t),0,-np.sin(t)],[0,1,0],[np.sin(t),0,np.cos(t)]])\n",
    "        elif roller==2:\n",
    "            return np.array([[np.cos(t),np.sin(t),0],[-np.sin(t),np.cos(t),0],[0,0,1]])\n",
    "\n",
    "    #Generate 3d grid or 4d tensor. Each grid represents a voxel. Each voxel represents the atom in it by onehot encoding of atomic type.\n",
    "    #Each complex in train set is rotated 9 times for data amplification.\n",
    "    #The complexes in core set are not rotated. \n",
    "    #The default resolution is 20*20*20.\n",
    "    def grid(self,grid, coords, features, frag_idx, resolution=1.0, max_dist=10.0,  rotation_bool=True, max_frag=10, rotations=9):\n",
    "        assert coords.shape[1] == 3\n",
    "        assert coords.shape[0] == features.shape[0]  \n",
    "\n",
    "        slider=frag_idx*20\n",
    "\n",
    "        x=y=z=np.array(range(-10,10),dtype=np.float32)+0.5\n",
    "        u=0\n",
    "        for i in range(len(coords)):\n",
    "            coord=coords[i]\n",
    "            # add/subtract 10 from the center\n",
    "            tmpx=abs(coord[0]-x)\n",
    "            tmpy=abs(coord[1]-y)\n",
    "            tmpz=abs(coord[2]-z)\n",
    "\n",
    "            if np.max(tmpx)<=19.5 and np.max(tmpy)<=19.5 and np.max(tmpz) <=19.5:\n",
    "                u+=1\n",
    "                # get the position of the closest point to coordinate which is found inside the grid\n",
    "                # append the features unto that slice\n",
    "                grid[0,slider+np.argmin(tmpx),slider+np.argmin(tmpy),slider+np.argmin(tmpz)] += features[i]\n",
    "                \n",
    "        if rotation_bool:\n",
    "            for rotation_idx in range(rotations):\n",
    "                theta = random.uniform(np.pi/18,np.pi/2)\n",
    "                roller = random.randrange(3)\n",
    "                coords = np.dot(coords, self.rotation_matrix(theta,roller))\n",
    "                for i in range(len(coords)):\n",
    "                    coord=coords[i]\n",
    "                    tmpx=abs(coord[0]-x)\n",
    "                    tmpy=abs(coord[1]-y)\n",
    "                    tmpz=abs(coord[2]-z)\n",
    "                    if np.max(tmpx)<=19.5 and np.max(tmpy)<=19.5 and np.max(tmpz) <=19.5:\n",
    "                        grid[rotation_idx+1,slider+np.argmin(tmpx),slider+np.argmin(tmpy),slider+np.argmin(tmpz)] += features[i]\n",
    "\n",
    "        return grid\n",
    "\n",
    "Feature = Feature_extractor()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Feature engineering of training set.\n",
    "train_complexes = []\n",
    "directory = os.getcwd()\n",
    "#for frag in range(70,77):\n",
    "pdb_id = '2x6w'\n",
    "\n",
    "for idx, row in df_plifSpecs.iterrows():\n",
    "    \n",
    "    temp_plifs_prot={}\n",
    "    temp_plifs_frag={}\n",
    "    ## do something with fragment_idx . i.e. open the pdb and do your shit with encoding\\\n",
    "    for aa_atm_coord_list, frag_lig_atm_coord_list, interaction, dist_list, aa_atm_asa_list, aa_asa_list in zip (row['AA_COORDS'], \n",
    "                                                                                       row['FRAGMENT_ATOMS_COORDS'],\n",
    "                                                                                       row['INTERACTION_TYPE'],\n",
    "                                                                                       row['DIST'],\n",
    "                                                                                       row['ATOM_SASA'],\n",
    "                                                                                       row['AA_SASA']):\n",
    "        # because sometimes salt bridges makes two concurrent connections so it is possible that we have one distance\n",
    "        # for two amino acids or ligand atoms! Encoding by atom is crazy fun\n",
    "        for dist, aa_atm_coord, frag_lig_atm_coord, aa_atm_asa, aa_asa in zip (dist_list, aa_atm_coord_list, \n",
    "                                                                         frag_lig_atm_coord_list,\n",
    "                                                                        aa_atm_asa_list,\n",
    "                                                                        aa_asa_list):\n",
    "            temp_plifs_prot[tuple(aa_atm_coord)]=[interaction,dist,aa_atm_asa,aa_asa]\n",
    "            temp_plifs_frag[tuple(frag_lig_atm_coord)]=[interaction,dist,aa_atm_asa,aa_asa]\n",
    "\n",
    "    \n",
    "    pdb = next(pybel.readfile('pdb',os.path.join(directory,'ATOM_' + pdb_id + '.pdb')))\n",
    "    ligand = next(pybel.readfile('pdb',os.path.join(directory, pdb_id + f'_{str(idx)}'+'.pdb')))\n",
    "    train_complexes.append((pdb,ligand,temp_plifs_prot,temp_plifs_frag))   \n",
    "    \n",
    "#ligand = next(pybel.readfile('pdb',os.path.join(directory,pdb_id + '_' + str(frag) + '.pdb')))\n",
    "\n",
    "train_grids=None\n",
    "rotations=9\n",
    "full_batch=10\n",
    "features_shape=76\n",
    "\n",
    "grid=np.zeros((full_batch,200,200,200,features_shape),dtype=np.float32)\n",
    "for idx, mols in enumerate(train_complexes):\n",
    "    coords1, features1 = Feature.get_features(mols[0],mols[2],1)\n",
    "    coords2, features2 = Feature.get_features(mols[1],mols[3],0)\n",
    "\n",
    "    # get the center point of protein\n",
    "    center=(np.max(coords2,axis=0)+np.min(coords2,axis=0))/2\n",
    "    coords=np.concatenate([coords1,coords2],axis = 0)\n",
    "    features=np.concatenate([features1,features2],axis = 0)\n",
    "    assert len(coords) == len(features)\n",
    "    # zero the coordinates \n",
    "    coords = coords-center\n",
    "    print(grid.shape)\n",
    "    grid=Feature.grid(grid,coords,features,idx, rotation_bool=True)\n",
    "if train_grids is None:\n",
    "    train_grids = grid\n",
    "else:\n",
    "    train_grids = np.concatenate([train_grids,grid],axis = 0)\n",
    "print('hi')\n",
    "with open('train_grids.pkl','wb') as f:\n",
    "    pickle.dump(train_grids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotations=9\n",
    "for j in range(rotations):\n",
    "    print(j+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c1eb98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from openbabel import pybel\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import openbabel\n",
    "import numpy as np\n",
    "from plip.structure.preparation import PDBComplex\n",
    "from plip.exchange.report import BindingSiteReport\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from biopandas.pdb import PandasPdb\n",
    "from Bio.PDB.SASA import ShrakeRupley\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class PLIF:\n",
    "    def __init__(self, PDB: str, MOL_SPLIT_START: int = 70, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(PLIF,self).__init__()\n",
    "        \n",
    "        self.MOL_SPLIT_START=MOL_SPLIT_START\n",
    "        self.pdb=PDB\n",
    "        self.records=['ATOM']\n",
    "        self.values=['HOH','CL','MG','ZN','MN','CA']\n",
    "        self.interaction_slices={\"hydrophobic\":[0,1,6,7,8,9,10],\n",
    "            \"hbond\":[0,1,7,11,13,15,16],\n",
    "            \"waterbridge\":[0,1,[6,7],11,13,16,17],\n",
    "            \"saltbridge\":[0,1,7,10,3,11,12],\n",
    "            \"pistacking\":[0,1,7,11,6,12,13],\n",
    "            \"pication\":[0,1,7,11,3,12,13],\n",
    "            \"halogen\":[0,1,7,10,12,14,15],\n",
    "            \"metal\":[0,1,11,8,6,17,16]} \n",
    "\n",
    "        self.column_names = ['RESNR', 'RESTYPE', 'DIST', 'LIG_IDX','PROT_IDX','FRAGMENT_ATOMS_COORDS', 'AA_COORDS']\n",
    "        self.path = os.getcwd()\n",
    "\n",
    "\n",
    "    def okToBreak(self, bond):\n",
    "        \"\"\"\n",
    "        Here we apply a bunch of rules to judge if the bond is OK to break.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bond :\n",
    "            RDkit MOL object\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Boolean :\n",
    "            OK or not to break.\n",
    "        \"\"\"\n",
    "        # See if the bond is in Ring (don't break that)\n",
    "        if bond.IsInRing():\n",
    "            return False\n",
    "        # We OK only single bonds to break\n",
    "        if bond.GetBondType() != Chem.rdchem.BondType.SINGLE:\n",
    "            return False\n",
    "\n",
    "        # Get the beginning atom of the bond\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        # Get the ending atom of the bond\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        # What kind of neighbors does these end and begenning atoms have? We need a family of no less than 5!\n",
    "        neighbor_end=list(end_atom.GetNeighbors())\n",
    "        neighbor_begin=list(begin_atom.GetNeighbors())\n",
    "        if (len(neighbor_end) + len(neighbor_begin)) <5:\n",
    "            return False\n",
    "        #for atm in neighbor_end:\n",
    "            #print(atm.GetAtomicNum())\n",
    "        #print(begin_atom.GetAtomicNum(), end_atom.GetAtomicNum(), MOL_SPLIT_START)\n",
    "        \n",
    "        # Now check if end or begenning atoms are in ring (we dont wanna bother those)\n",
    "        if not(begin_atom.IsInRing() or end_atom.IsInRing()):\n",
    "            return False\n",
    "        elif begin_atom.GetAtomicNum() >= self.MOL_SPLIT_START or \\\n",
    "                end_atom.GetAtomicNum() >= self.MOL_SPLIT_START:\n",
    "            return False\n",
    "        elif end_atom.GetAtomicNum() == 1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def undo_id_label (self, frag, split_id):\n",
    "        # I am trying to restore Hydrogens where the break happened\n",
    "        for i, atom in enumerate(frag.GetAtoms()):\n",
    "            if atom.GetAtomicNum() >= split_id:\n",
    "                atom.SetAtomicNum(1)\n",
    "\n",
    "        return frag\n",
    "\n",
    "    # Divide a molecule into fragments\n",
    "    def split_molecule(self, mol, pdb):\n",
    "\n",
    "        split_id = self.MOL_SPLIT_START\n",
    "\n",
    "        res = []\n",
    "        res_no_id=[]\n",
    "\n",
    "        to_check = [mol]\n",
    "        while len(to_check) > 0:\n",
    "            ms = self.spf(to_check.pop(), split_id)\n",
    "            if len(ms) == 1:\n",
    "                res += ms\n",
    "            else:\n",
    "                to_check += ms\n",
    "                split_id += 1\n",
    "        for frag in res:\n",
    "            res_no_id.append(self.undo_id_label(frag, self.MOL_SPLIT_START))\n",
    "\n",
    "        res_pdb_frags=[]\n",
    "\n",
    "        for idx, frag in enumerate(res_no_id):\n",
    "            w = Chem.PDBWriter(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "            w.write(frag)\n",
    "            w.close()\n",
    "            \n",
    "            unwanted_entries= ['CONECT', 'END']            \n",
    "            with open(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as oldfile, open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as newfile:\n",
    "                for line in oldfile:\n",
    "                    if not any(unwanted_entry in line for unwanted_entry in unwanted_entries):\n",
    "                        newfile.write(line)\n",
    "\n",
    "                    \n",
    "            data = data2 = \"\"\n",
    "\n",
    "            # Reading data from file1\n",
    "            with open(f\"ATOM_{pdb}.pdb\") as fp:\n",
    "                data = fp.read()\n",
    "\n",
    "            # Reading data from file2\n",
    "\n",
    "            with open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as fp:\n",
    "                data2 = fp.read()\n",
    "            \n",
    "            # Merging 2 files\n",
    "            # To add the data of file2\n",
    "            # from next line\n",
    "            #data += \"\\n\"\n",
    "            data += data2\n",
    "            \n",
    "            with open(f\"HOH_{pdb}.pdb\") as fp:\n",
    "                data3 = fp.read()\n",
    "            data += data3\n",
    "\n",
    "            with open (f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as fp:\n",
    "                fp.write(data)\n",
    "            res_pdb_frags.append(f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "        return res_pdb_frags #create_chain(res)\n",
    "\n",
    "\n",
    "    # Function for doing all the nitty gritty splitting work.\n",
    "    # loops over bonds until bonds get exhausted or bonds are ok to break, whichever comes first. If ok to break, then each\n",
    "    # fragment needs to be checked individually again through the loop\n",
    "    def spf(self, mol, split_id):\n",
    "\n",
    "        bonds = mol.GetBonds()\n",
    "        for i in range(len(bonds)):\n",
    "            if self.okToBreak(bonds[i]):\n",
    "                mol = Chem.FragmentOnBonds(mol, [i])\n",
    "                # Dummy atoms are always added last\n",
    "                n_at = mol.GetNumAtoms()\n",
    "                print('Split ID', split_id)\n",
    "                mol.GetAtomWithIdx(n_at-1).SetAtomicNum(split_id)\n",
    "                mol.GetAtomWithIdx(n_at-2).SetAtomicNum(split_id)\n",
    "                return Chem.rdmolops.GetMolFrags(mol, asMols=True)\n",
    "\n",
    "        # If the molecule could not been split, return original molecule\n",
    "        return [mol]\n",
    "    #get_fragments(fragment_mols)\n",
    "\n",
    "    def retreive_plip_interactions(self, pdb_file):\n",
    "        \"\"\"\n",
    "        Retreives the interactions from PLIP.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdb_file :\n",
    "            The PDB file of the complex. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict :\n",
    "            A dictionary of the binding sites and the interactions.\n",
    "        \"\"\"\n",
    "        protlig = PDBComplex()   #instantiate the loader from PLIP\n",
    "        protlig.load_pdb(pdb_file)   # load the pdb file\n",
    "        for ligand in protlig.ligands:\n",
    "            protlig.characterize_complex(ligand)   # find ligands and analyze interactions\n",
    "        sites = {}\n",
    "        # loop over binding sites\n",
    "        for key, site in sorted(protlig.interaction_sets.items()):\n",
    "            binding_site = BindingSiteReport(site)   # collect data about interactions\n",
    "            # tuples of *_features and *_info will be converted to pandas DataFrame\n",
    "            keys = (\n",
    "                \"hydrophobic\",\n",
    "                \"hbond\",\n",
    "                \"waterbridge\",\n",
    "                \"saltbridge\",\n",
    "                \"pistacking\",\n",
    "                \"pication\",\n",
    "                \"halogen\",\n",
    "                \"metal\"\n",
    "            )\n",
    "        # interactions is a dictionary which contains relevant information for each\n",
    "        # of the possible interactions: hydrophobic, hbond, etc. in the considered\n",
    "        # binding site. Each interaction contains a list with \n",
    "        # 1. the features of that interaction, e.g. for hydrophobic:\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "        # 2. information for each of these features, e.g. for hydrophobic\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "\n",
    "            interactions = {\n",
    "                k: [getattr(binding_site, k + \"_features\")] + getattr(binding_site, k + \"_info\")\n",
    "                for k in keys\n",
    "            }\n",
    "            sites[key] = interactions\n",
    "        return sites\n",
    "\n",
    "    def get_coords_prot(self, RESNR):\n",
    "        ppdb = PandasPdb()\n",
    "        ppdb.read_pdb(f\"{self.pdb.split('.')[0]}_protein.pdb\")\n",
    "        only_protein=ppdb.df['ATOM']\n",
    "        resnr_coords=[]\n",
    "        for i in RESNR:\n",
    "            resnr_coords.append(list(only_protein[only_protein['atom_number']==int(i)][['x_coord', 'y_coord', 'z_coord']].values[0]))\n",
    "        return resnr_coords\n",
    "    \n",
    "    ### the most slow function out of all this garbage code ###\n",
    "    def aa_descriptors_asa(self, fragment_idx, aa, coords, extra_feats):\n",
    "        print('aa', aa)\n",
    "        \n",
    "        print('\\n')\n",
    "        print('coords', coords)\n",
    "        print('\\n')\n",
    "        print('extra_faats', extra_feats)\n",
    "        p = PDBParser(QUIET=1)\n",
    "        structure = p.get_structure(self.pdb.split('.')[0], f\"ATOM_{self.pdb.split('.')[0]}_{fragment_idx}.pdb\")\n",
    "        sr = ShrakeRupley()\n",
    "        print(f\"ATOM_{self.pdb.split('.')[0]}_{fragment_idx}.pdb\")\n",
    "        sasa_res=[]\n",
    "        sasa_atom=[]\n",
    "\n",
    "        for a in aa: \n",
    "            for chain in structure[0]:\n",
    "                for res in chain:\n",
    "                    if f'={a} ' in str(res.__repr__()):\n",
    "                        sr.compute(structure[0], level=\"R\")\n",
    "                        sasa_res.append(round(res.sasa,2))\n",
    "                        sr.compute(structure[0], level=\"A\")\n",
    "                        for coor in coords:\n",
    "                            for atom in res:\n",
    "                                if [round(item) for item in atom.get_coord()] == [round(np.float32(item)) for item in coor]:\n",
    "                                    sasa_atom.append(round(atom.sasa,2))\n",
    "\n",
    "#                         #if all(v == 0.0 for v in sasas):\n",
    "                        if not sasa_atom:\n",
    "                            try:\n",
    "                                coords=self.get_coords_prot(extra_feats[0].split(',') if ',' in extra_feats[0] \\\n",
    "                                                               else extra_feats)\n",
    "                                for coor in coords:\n",
    "                                    for atom in res:\n",
    "                                        if [round(item) for item in atom.get_coord()] == [round(np.float32(item)) for item in coor]:\n",
    "                                            sasa_atom.append(round(atom.sasa,2))\n",
    "                            except Exception:\n",
    "                                print(f\"no SASA for AA idx {a}'s atom'\")\n",
    "                                \n",
    "                \n",
    "        return [sasa_atom], [sasa_res] , coords\n",
    "                \n",
    "    def interaction_df(self, split):\n",
    "\n",
    "        all_interactions_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        # We create the dictionary for the complex of interest:\n",
    "        for idx, s in enumerate(split):\n",
    "\n",
    "            pdb_id=s.split('.')[0]\n",
    "            raw=pdb_id.split('_')[1]\n",
    "            idx_frag=int(pdb_id.split('_')[2])\n",
    "            interactions_by_site = self.retreive_plip_interactions(f\"{pdb_id}.pdb\")\n",
    "\n",
    "            # Let’s see how many binding sites are detected:\n",
    "\n",
    "    #         print(\n",
    "    #             f\"Number of binding sites detected in {pdb_id} : \"\n",
    "    #             f\"{len(interactions_by_site)}\\n\"\n",
    "    #             f\"with {interactions_by_site.keys()}\"\n",
    "    #         )\n",
    "            # In this case, the first binding site containing ligand 03P will be further investigated.\n",
    "            index_of_selected_site = 0\n",
    "            selected_site = list(interactions_by_site.keys())[index_of_selected_site]\n",
    "            #print(selected_site)\n",
    "\n",
    "\n",
    "            valid_types = [\n",
    "                    \"hydrophobic\",\n",
    "                    \"hbond\",\n",
    "                    \"waterbridge\",\n",
    "                    \"saltbridge\",\n",
    "                    \"pistacking\",\n",
    "                    \"pication\",\n",
    "                    \"halogen\",\n",
    "                    \"metal\",\n",
    "                ]\n",
    "\n",
    "            for _type in valid_types:\n",
    "                output_df=self.create_df_from_binding_site(raw, interactions_by_site[selected_site], idx+self.MOL_SPLIT_START, selected_site,\n",
    "                                                      interactions_by_site,\n",
    "                                                      interaction_type=_type)\n",
    "                all_interactions_df=all_interactions_df.append(output_df)\n",
    "        all_interactions_df = all_interactions_df[all_interactions_df['RESNR'].notna()]\n",
    "        all_interactions_df.to_csv(f\"{self.path}/results_plifs/{raw}_plifs_and_properties.csv\", index=False)\n",
    "        return all_interactions_df\n",
    "\n",
    "\n",
    "    # We can construct a pandas.DataFrame for a binding site and particular interaction type.\n",
    "\n",
    "    def create_df_from_binding_site(self, raw, selected_site_interactions, fragment_idx, selected_site, \n",
    "                                    interactions_by_site, interaction_type=\"hbond\"):\n",
    "        \"\"\"\n",
    "        Creates a data frame from a binding site and interaction type.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selected_site_interactions : dict\n",
    "            Precalculated interactions from PLIP for the selected site\n",
    "        interaction_type : str\n",
    "            The interaction type of interest (default set to hydrogen bonding).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame :\n",
    "            DataFrame with information retreived from PLIP.\n",
    "        \"\"\"\n",
    "        # check if interaction type is valid:\n",
    "        valid_types = [\n",
    "            \"hydrophobic\",\n",
    "            \"hbond\",\n",
    "            \"waterbridge\",\n",
    "            \"saltbridge\",\n",
    "            \"pistacking\",\n",
    "            \"pication\",\n",
    "            \"halogen\",\n",
    "            \"metal\",\n",
    "        ]\n",
    "\n",
    "\n",
    "        if interaction_type not in valid_types:\n",
    "            print(\"!!! Wrong interaction type specified. Hbond is chosen by default !!! \\n\")\n",
    "            interaction_type = \"hbond\"\n",
    "\n",
    "        def interaction_values(n):\n",
    "            try:\n",
    "                interactions=interactions_by_site[selected_site][interaction_type]\n",
    "                if type(n) is list:\n",
    "                    return [interactions[1:][x][i] for x in \n",
    "                        range(len(interactions[1:])) for i in n]\n",
    "                else:\n",
    "                    return [interactions[1:][x][n] for x in \n",
    "                        range(len(interactions[1:]))]\n",
    "            except Exception:\n",
    "                return None\n",
    "            \n",
    "        if interactions_by_site[selected_site][interaction_type][1:]:\n",
    "            #print(list(map(interaction_values, self.interaction_slices[interaction_type])), self.column_names)\n",
    "            selected_feats=list(map(interaction_values, self.interaction_slices[interaction_type]))\n",
    "            #print(selected_feats)\n",
    "            try: \n",
    "                if int(selected_feats[4])>int(selected_feats[3]):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3]  \n",
    "            except: \n",
    "                if int(any(selected_feats[4]))>int(any(selected_feats[3])):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3] \n",
    "            df = pd.DataFrame(\n",
    "                # data is stored AFTER the columns names\n",
    "                [selected_feats],\n",
    "                # column names are always the first element - we skipped that in the above - we are gonna use that for naming the df\n",
    "                columns = self.column_names\n",
    "            )\n",
    "\n",
    "            df[\"INTERACTION_TYPE\"]=interaction_type\n",
    "            print( [list(x) for x in selected_feats[6]])\n",
    "            df[\"ATOM_SASA\"], df[\"AA_SASA\"], extra_coords = self.aa_descriptors_asa(fragment_idx,selected_feats[0],\n",
    "                                                                  [list(x) for x in selected_feats[6]],\n",
    "                                                                 selected_feats[4]) \n",
    "                                                                  #df[\"AA_COORDS\"].values[0])\n",
    "            df[\"AA_COORDS\"]=[extra_coords]\n",
    "                #[self.get_coords_prot(selected_feats[4].split(','))]\n",
    "            df[\"FRAGMENT_ATOMS_COORDS\"]=[selected_feats[5]]\n",
    "                            #[self.get_coords_lig(selected_feats[3].split(','))]    \n",
    "            df['FRAGMENT_ID']=fragment_idx\n",
    "\n",
    "            # ideally we would like to exclude waters from further processing. Threrfore let us reduce any waterbridge \n",
    "            # interaction to the eucladean distance in order to omit water\n",
    "            \n",
    "            if interaction_type == \"waterbridge\":\n",
    "                df['DIST']=[[np.linalg.norm(x) for x in df['DIST'].to_numpy()]]\n",
    "                \n",
    "            # also deal with one distance value and two coords, this is common in saltbridge interactions:\n",
    "            if len(extra_coords) == len(selected_feats[2])*2:\n",
    "                df['DIST']=[selected_feats[2] + selected_feats[2]]\n",
    "                \n",
    "        else:\n",
    "\n",
    "            df= pd.DataFrame({'RESNR':[None], 'RESTYPE':[None], 'DIST':[None], 'LIG_IDX':[None],'PROT_IDX':[None],\n",
    "                        'INTERACTION_TYPE':[interaction_type], \"AA_COORDS\": [None], \"FRAGMENT_ATOMS_COORDS\":[None],\n",
    "                        \"ATOM_SASA\":[None],\"AA_SASA\":[None],\n",
    "                              'FRAGMENT_ID':[str(fragment_idx)]})\n",
    "\n",
    "\n",
    "\n",
    "        return df\n",
    "    def pdb_2_sdf(self, pdb):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"pdb\", \"sdf\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, pdb)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "\n",
    "\n",
    "        obConversion.WriteFile(mol, f\"{pdb.split('.')[0]}.sdf\")\n",
    "        return f\"{pdb.split('.')[0]}.sdf\"\n",
    "    \n",
    "    def sdf_2_pdb(self, sdf):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"sdf\", \"pdb\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, sdf)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "        obConversion.WriteFile(mol, f\"{sdf.split('.')[0]}.pdb\")\n",
    "        return f\"HETATM_{sdf.split('.')[0]}.pdb\"\n",
    "\n",
    "    def save_bpdb(self, pdb,ppdb, record):  \n",
    "        ppdb.to_pdb(path=f\"{record}_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                    records=[record],\n",
    "                    gz=False, \n",
    "                    append_newline=True)\n",
    "\n",
    "    def get_HOH_pdb(self, pdb):\n",
    "        ppdb = PandasPdb() \n",
    "        ppdb.read_pdb(pdb) \n",
    "        ppdb.df['HETATM']=ppdb.df['HETATM'].loc[ppdb.df['HETATM']['residue_name'].isin(self.values)]\n",
    "        ppdb.to_pdb(path=f\"HOH_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                records=['HETATM'],\n",
    "                gz=False, \n",
    "                append_newline=True)\n",
    "\n",
    "    def keep_relevant_hetatm(self, pdb):\n",
    "        \n",
    "        with open(pdb) as f1, open(f\"ATOM_{pdb.split('.')[0].split('_')[0]}.pdb\", 'w') as f2:\n",
    "            for line in f1:\n",
    "                if 'ATOM' in line:\n",
    "                    f2.write(line)\n",
    "                    \n",
    "        self.get_HOH_pdb(pdb)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def fragment_and_plif(self):\n",
    "        path = os.getcwd()\n",
    "        if not os.path.exists('results_plifs'):\n",
    "            os.mkdir(f'{path}/results_plifs')\n",
    "         \n",
    "        raw=str(self.pdb).split('.')[0]\n",
    "        self.keep_relevant_hetatm(f'{raw}_protein.pdb')\n",
    "        self.sdf_2_pdb(f'{raw}_ligand.sdf')\n",
    "        fragment_mols = Chem.SDMolSupplier(str(f'{raw}_ligand.sdf'), removeHs=True, sanitize=False)\n",
    "        try: fragment_mols = Chem.RemoveHs(fragment_mols[0])\n",
    "        except: fragment_mols = AllChem.MolFromPDBFile(f'{raw}_ligand.pdb')\n",
    "        output_df = self.interaction_df(self.split_molecule(fragment_mols,raw))\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "#         for filePath in fileList:\n",
    "#             try:\n",
    "#                 os.remove(filePath)\n",
    "#             except:\n",
    "#                 print(\"Error while deleting file : \", filePath)\n",
    "#         os.chdir(f'{path}')\n",
    "        \n",
    "        return output_df.groupby('FRAGMENT_ID')['AA_COORDS', 'FRAGMENT_ATOMS_COORDS','INTERACTION_TYPE','DIST','ATOM_SASA','AA_SASA'].agg(list)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    p_directory = os.getcwd()\n",
    "    \n",
    "    pdb_id = '1ro6'\n",
    "    os.chdir(f'/groups/cherkasvgrp/share/progressive_docking/hmslati/plif_cnn/general_refined_set/{pdb_id}')\n",
    "\n",
    "    df_plifSpecs = PLIF(PDB = f'{pdb_id}.pdb').fragment_and_plif()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d961c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "raw='1ro6'\n",
    "fileList = []\n",
    "fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except:\n",
    "        print(\"Error while deleting file : \", filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=[16, 19, 51, 189, 275]\n",
    "\n",
    "\n",
    "coords=[[35.822, 68.814, 25.109], [35.822, 68.814, 25.109], [35.822, 68.814, 25.109], [35.822, 68.814, 25.109], [35.822, 68.814, 25.109]]\n",
    "\n",
    "\n",
    "extra_faats=[2781, 2781, 2781, 2781, 2781]\n",
    "p = PDBParser(QUIET=1)\n",
    "structure = p.get_structure(\"1ro6\", f\"ATOM_1ro6_70.pdb\")\n",
    "sr = ShrakeRupley()\n",
    "sasa_res=[]\n",
    "sasa_atom=[]\n",
    "\n",
    "for a in aa: \n",
    "    for chain in structure[0]:\n",
    "        for res in chain:\n",
    "            if f'={a} ' in str(res.__repr__()):\n",
    "                sr.compute(structure[0], level=\"R\")\n",
    "                sasa_res.append(round(res.sasa,2))\n",
    "                sr.compute(structure[0], level=\"A\")\n",
    "                for coor in coords:\n",
    "                    for atom in res:\n",
    "                        if [round(item) for item in atom.get_coord()] == [round(np.float32(item)) for item in coor]:\n",
    "                            sasa_atom.append(round(atom.sasa,2))\n",
    "\n",
    "#                         #if all(v == 0.0 for v in sasas):\n",
    "                if not sasa_atom:\n",
    "                    try:\n",
    "                        coords=self.get_coords_prot(extra_feats[0].split(',') if ',' in extra_feats[0] \\\n",
    "                                                       else extra_feats)\n",
    "                        for coor in coords:\n",
    "                            for atom in res:\n",
    "                                if [round(item) for item in atom.get_coord()] == [round(np.float32(item)) for item in coor]:\n",
    "                                    sasa_atom.append(round(atom.sasa,2))\n",
    "                    except Exception:\n",
    "                        print(f\"no SASA for AA idx {a}'s atom'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plifSpecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4f14b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdb_id 2gbf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 686\u001b[0m\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while deleting file : \u001b[39m\u001b[38;5;124m\"\u001b[39m, filePath)\n\u001b[0;32m--> 686\u001b[0m df_plifSpecs \u001b[38;5;241m=\u001b[39m \u001b[43mPLIF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDB\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpdb_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pdb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfragment_and_plif\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m train_label\u001b[38;5;241m.\u001b[39mextend([row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKd/Ki\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    690\u001b[0m single_pdb_frags \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn [1], line 600\u001b[0m, in \u001b[0;36mPLIF.fragment_and_plif\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/results_plifs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    599\u001b[0m raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdb)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 600\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_relevant_hetatm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mraw\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_protein.pdb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msdf_2_pdb(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ligand.sdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    602\u001b[0m fragment_mols \u001b[38;5;241m=\u001b[39m Chem\u001b[38;5;241m.\u001b[39mSDMolSupplier(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ligand.sdf\u001b[39m\u001b[38;5;124m'\u001b[39m), removeHs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sanitize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [1], line 590\u001b[0m, in \u001b[0;36mPLIF.keep_relevant_hetatm\u001b[0;34m(self, pdb)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATOM\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line:\n\u001b[1;32m    588\u001b[0m             f2\u001b[38;5;241m.\u001b[39mwrite(line)\n\u001b[0;32m--> 590\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_HOH_pdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [1], line 579\u001b[0m, in \u001b[0;36mPLIF.get_HOH_pdb\u001b[0;34m(self, pdb)\u001b[0m\n\u001b[1;32m    577\u001b[0m ppdb\u001b[38;5;241m.\u001b[39mread_pdb(pdb) \n\u001b[1;32m    578\u001b[0m ppdb\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHETATM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mppdb\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHETATM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[ppdb\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHETATM\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresidue_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)]\n\u001b[0;32m--> 579\u001b[0m \u001b[43mppdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHOH_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pdb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHETATM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappend_newline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/plifs/lib/python3.8/site-packages/biopandas/pdb/pandas_pdb.py:645\u001b[0m, in \u001b[0;36mPandasPdb.to_pdb\u001b[0;34m(self, path, records, gz, append_newline)\u001b[0m\n\u001b[1;32m    642\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 645\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mline_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m openf(path, w_mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.conda/envs/plifs/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/plifs/lib/python3.8/site-packages/pandas/core/reshape/concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/.conda/envs/plifs/lib/python3.8/site-packages/pandas/core/reshape/concat.py:404\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    401\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from openbabel import pybel\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import openbabel\n",
    "import numpy as np\n",
    "from plip.structure.preparation import PDBComplex\n",
    "from plip.exchange.report import BindingSiteReport\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from biopandas.pdb import PandasPdb\n",
    "from Bio.PDB.SASA import ShrakeRupley\n",
    "from Bio.PDB import PDBParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# PLEASE TRY TO READ -> 45次实验分别进行10倍交叉验证，取平均\n",
    "\n",
    "#Converts the protein-ligand complexes into 4D tensor. \n",
    "class Feature_extractor():\n",
    "    def __init__(self):\n",
    "        self.atom_codes = {}\n",
    "        #'others' includs metal atoms and B atom. There are no B atoms on training and test sets. \n",
    "        # 55 to 63 will be reserved to PLIF features as follows:\n",
    "        # 55: hydrophobic\n",
    "        # 56: hbond\n",
    "        # 57: waterbridge\n",
    "        # 58: saltbridge\n",
    "        # 59: pistacking\n",
    "        # 60: pication\n",
    "        # 61: halogen\n",
    "        # 62: metal\n",
    "        # 63: Distances \n",
    "        \n",
    "        # others = ([3,4,5,11,12,13]+list(range(19,32))+list(range(37,51))+list(range(55,84)))\n",
    "        plif_specs=list(range(55,64))\n",
    "        #C and N atoms can be hybridized in three ways and S atom can be hybridized in two ways here. \n",
    "        #Hydrogen atom is also considered for feature extraction. I think phosphor atom has 3 or 5 as hyb states but \n",
    "        # in biological system its usually the same recurrent phosphate even in most small molecules so safe to assume one\n",
    "        # hybridization state for this purpose. \n",
    "        atom_types = [1,(6,1),(6,2),(6,3),(7,1),(7,2),(7,3),8,15,(16,2),(16,3),\n",
    "                      34,9,17,35,53,11,12,13,14,5,19,20,25,29,28,30]+plif_specs\n",
    "      \n",
    "        for i, j in enumerate(atom_types):\n",
    "            if type(j) is list:\n",
    "                for k in j:\n",
    "                    self.atom_codes[k] = i\n",
    "                \n",
    "            else:\n",
    "                self.atom_codes[j] = i              \n",
    "        \n",
    "        self.sum_atom_types = len(atom_types)\n",
    "        \n",
    "    #Onehot encoding of each atom. The atoms in protein or ligand are treated separately.\n",
    "    def encode(self, atomic_num, orig_coords, plifs, molprotein):\n",
    "        encoding = np.zeros(self.sum_atom_types*2)\n",
    "        if molprotein == 1:\n",
    "            encoding[self.atom_codes[atomic_num]] = 1.0\n",
    "            for coord, plif_feats in plifs.items():\n",
    "                if [round(item) for item in coord] == [round(item) for item in orig_coords]:\n",
    "                    encoding[self.atom_codes[55]] = 1.0 if plifs[coord][0] == 'hydrophobic' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[56]] = 1.0 if plifs[coord][0] == 'hbond' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[57]] = 1.0 if plifs[coord][0] == 'waterbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[58]] = 1.0 if plifs[coord][0] == 'saltbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[59]] = 1.0 if plifs[coord][0] == 'pistacking' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[60]] = 1.0 if plifs[coord][0] == 'pication' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[61]] = 1.0 if plifs[coord][0] == 'halogen' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[62]] = 1.0 if plifs[coord][0] == 'metal' \\\n",
    "                    else 0.0\n",
    "                    \n",
    "                    #distance\n",
    "                    encoding[self.atom_codes[63]] = plifs[coord][1]\n",
    "                    \n",
    "\n",
    "                \n",
    "        else:\n",
    "            encoding[self.sum_atom_types+self.atom_codes[atomic_num]] = 1.0\n",
    "            for coord, plif_feats in plifs.items():\n",
    "                if [round(item) for item in coord] == [round(item) for item in orig_coords]:\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[55]] = 1.0 if plifs[coord][0] == 'hydrophobic' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[56]] = 1.0 if plifs[coord][0] == 'hbond' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[57]] = 1.0 if plifs[coord][0] == 'waterbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[58]] = 1.0 if plifs[coord][0] == 'saltbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[59]] = 1.0 if plifs[coord][0] == 'pistacking' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[60]] = 1.0 if plifs[coord][0] == 'pication' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[61]] = 1.0 if plifs[coord][0] == 'halogen' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[62]] = 1.0 if plifs[coord][0] == 'metal' \\\n",
    "                    else 0.0\n",
    "                    \n",
    "                    #distance\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[63]] = plifs[coord][1]\n",
    "\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    #Get atom coords and atom features from the complexes.   \n",
    "    def get_features(self, molecule, plifs, molprotein):\n",
    "        coords = []\n",
    "        features = []\n",
    "            \n",
    "        for atom in molecule:\n",
    "            coords.append(atom.coords)\n",
    "            if atom.atomicnum in [6,7,16]:\n",
    "                atomicnum = (atom.atomicnum,atom.hyb)\n",
    "                features.append(self.encode(atomicnum,atom.coords,plifs,molprotein))\n",
    "            else:\n",
    "                features.append(self.encode(atom.atomicnum,atom.coords,plifs,molprotein))\n",
    "        \n",
    "        coords = np.array(coords, dtype=np.float32)\n",
    "        features = np.array(features, dtype=np.float32)\n",
    "\n",
    "        return coords, features\n",
    "     \n",
    "    #Define the rotation matrixs of 3D stuctures.\n",
    "    def rotation_matrix(self, t, roller):\n",
    "        if roller==0:\n",
    "            return np.array([[1,0,0],[0,np.cos(t),np.sin(t)],[0,-np.sin(t),np.cos(t)]])\n",
    "        elif roller==1:\n",
    "            return np.array([[np.cos(t),0,-np.sin(t)],[0,1,0],[np.sin(t),0,np.cos(t)]])\n",
    "        elif roller==2:\n",
    "            return np.array([[np.cos(t),np.sin(t),0],[-np.sin(t),np.cos(t),0],[0,0,1]])\n",
    "\n",
    "    #Generate 3d grid or 4d tensor. Each grid represents a voxel. Each voxel represents the atom in it by onehot encoding of atomic type.\n",
    "    #Each complex in train set is rotated 9 times for data amplification.\n",
    "    #The complexes in core set are not rotated. \n",
    "    #The default resolution is 20*20*20.\n",
    "    def grid(self,grid, coords, features, frag_idx, resolution=1.0, max_dist=10.0,  rotation_bool=True, max_frag=10, rotations=9):\n",
    "        assert coords.shape[1] == 3\n",
    "        assert coords.shape[0] == features.shape[0]  \n",
    "\n",
    "        slider=frag_idx*20\n",
    "        print(slider)\n",
    "\n",
    "        x=y=z=np.array(range(-10,10),dtype=np.float32)+0.5\n",
    "        u=0\n",
    "        for i in range(len(coords)):\n",
    "            coord=coords[i]\n",
    "            # add/subtract 10 from the center\n",
    "            tmpx=abs(coord[0]-x)\n",
    "            tmpy=abs(coord[1]-y)\n",
    "            tmpz=abs(coord[2]-z)\n",
    "\n",
    "            if np.max(tmpx)<=19.5 and np.max(tmpy)<=19.5 and np.max(tmpz) <=19.5:\n",
    "                u+=1\n",
    "                # get the position of the closest point to coordinate which is found inside the grid\n",
    "                # append the features unto that slice\n",
    "                grid[0,slider+np.argmin(tmpx),slider+np.argmin(tmpy),slider+np.argmin(tmpz)] += features[i]\n",
    "                \n",
    "        if rotation_bool:\n",
    "            for rotation_idx in range(rotations):\n",
    "                theta = random.uniform(np.pi/18,np.pi/2)\n",
    "                roller = random.randrange(3)\n",
    "                coords = np.dot(coords, self.rotation_matrix(theta,roller))\n",
    "                for i in range(len(coords)):\n",
    "                    coord=coords[i]\n",
    "                    tmpx=abs(coord[0]-x)\n",
    "                    tmpy=abs(coord[1]-y)\n",
    "                    tmpz=abs(coord[2]-z)\n",
    "                    if np.max(tmpx)<=19.5 and np.max(tmpy)<=19.5 and np.max(tmpz) <=19.5:\n",
    "                        grid[rotation_idx+1,slider+np.argmin(tmpx),slider+np.argmin(tmpy),slider+np.argmin(tmpz)] += features[i]\n",
    "\n",
    "        return grid\n",
    "    \n",
    "class PLIF:\n",
    "    def __init__(self, PDB: str, MOL_SPLIT_START: int = 70, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(PLIF,self).__init__()\n",
    "        \n",
    "        self.MOL_SPLIT_START=MOL_SPLIT_START\n",
    "        self.pdb=PDB\n",
    "        self.records=['ATOM']\n",
    "        self.values=['HOH','CL','MG','ZN','MN','CA']\n",
    "        self.interaction_slices={\"hydrophobic\":[0,1,6,7,8,9,10],\n",
    "            \"hbond\":[0,1,7,11,13,15,16],\n",
    "            \"waterbridge\":[0,1,[6,7],11,13,16,17],\n",
    "            \"saltbridge\":[0,1,7,10,3,11,12],\n",
    "            \"pistacking\":[0,1,7,11,6,12,13],\n",
    "            \"pication\":[0,1,7,11,3,12,13],\n",
    "            \"halogen\":[0,1,7,10,12,14,15],\n",
    "            \"metal\":[0,1,11,8,6,17,16]} \n",
    "\n",
    "        self.column_names = ['RESNR', 'RESTYPE', 'DIST', 'LIG_IDX','PROT_IDX','FRAGMENT_ATOMS_COORDS', 'AA_COORDS']\n",
    "        self.path = os.getcwd()\n",
    "\n",
    "\n",
    "    def okToBreak(self, bond):\n",
    "        \"\"\"\n",
    "        Here we apply a bunch of rules to judge if the bond is OK to break.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bond :\n",
    "            RDkit MOL object\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Boolean :\n",
    "            OK or not to break.\n",
    "        \"\"\"\n",
    "        # See if the bond is in Ring (don't break that)\n",
    "        if bond.IsInRing():\n",
    "            return False\n",
    "        # We OK only single bonds to break\n",
    "        if bond.GetBondType() != Chem.rdchem.BondType.SINGLE:\n",
    "            return False\n",
    "\n",
    "        # Get the beginning atom of the bond\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        # Get the ending atom of the bond\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        # What kind of neighbors does these end and begenning atoms have? We need a family of no less than 5!\n",
    "        neighbor_end=list(end_atom.GetNeighbors())\n",
    "        neighbor_begin=list(begin_atom.GetNeighbors())\n",
    "        if (len(neighbor_end) + len(neighbor_begin)) <5:\n",
    "            return False\n",
    "        #for atm in neighbor_end:\n",
    "            #print(atm.GetAtomicNum())\n",
    "        #print(begin_atom.GetAtomicNum(), end_atom.GetAtomicNum(), MOL_SPLIT_START)\n",
    "        \n",
    "        # Now check if end or begenning atoms are in ring (we dont wanna bother those)\n",
    "        if not(begin_atom.IsInRing() or end_atom.IsInRing()):\n",
    "            return False\n",
    "        elif begin_atom.GetAtomicNum() >= self.MOL_SPLIT_START or \\\n",
    "                end_atom.GetAtomicNum() >= self.MOL_SPLIT_START:\n",
    "            return False\n",
    "        elif end_atom.GetAtomicNum() == 1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def undo_id_label (self, frag, split_id):\n",
    "        # I am trying to restore Hydrogens where the break happened\n",
    "        for i, atom in enumerate(frag.GetAtoms()):\n",
    "            if atom.GetAtomicNum() >= split_id:\n",
    "                atom.SetAtomicNum(1)\n",
    "\n",
    "        return frag\n",
    "\n",
    "    # Divide a molecule into fragments\n",
    "    def split_molecule(self, mol, pdb):\n",
    "\n",
    "        split_id = self.MOL_SPLIT_START\n",
    "\n",
    "        res = []\n",
    "        res_no_id=[]\n",
    "\n",
    "        to_check = [mol]\n",
    "        while len(to_check) > 0:\n",
    "            ms = self.spf(to_check.pop(), split_id)\n",
    "            if len(ms) == 1:\n",
    "                res += ms\n",
    "            else:\n",
    "                to_check += ms\n",
    "                split_id += 1\n",
    "        for frag in res:\n",
    "            res_no_id.append(self.undo_id_label(frag, self.MOL_SPLIT_START))\n",
    "\n",
    "        res_pdb_frags=[]\n",
    "\n",
    "        for idx, frag in enumerate(res_no_id):\n",
    "            w = Chem.PDBWriter(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "            w.write(frag)\n",
    "            w.close()\n",
    "            \n",
    "            unwanted_entries= ['CONECT', 'END']            \n",
    "            with open(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as oldfile, open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as newfile:\n",
    "                for line in oldfile:\n",
    "                    if not any(unwanted_entry in line for unwanted_entry in unwanted_entries):\n",
    "                        newfile.write(line)\n",
    "\n",
    "                    \n",
    "            data = data2 = \"\"\n",
    "\n",
    "            # Reading data from file1\n",
    "            with open(f\"ATOM_{pdb}.pdb\") as fp:\n",
    "                data = fp.read()\n",
    "\n",
    "            # Reading data from file2\n",
    "\n",
    "            with open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as fp:\n",
    "                data2 = fp.read()\n",
    "            \n",
    "            # Merging 2 files\n",
    "            # To add the data of file2\n",
    "            # from next line\n",
    "            #data += \"\\n\"\n",
    "            data += data2\n",
    "            \n",
    "            with open(f\"HOH_{pdb}.pdb\") as fp:\n",
    "                data3 = fp.read()\n",
    "            data += data3\n",
    "\n",
    "            with open (f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as fp:\n",
    "                fp.write(data)\n",
    "            res_pdb_frags.append(f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "        return res_pdb_frags #create_chain(res)\n",
    "\n",
    "\n",
    "    # Function for doing all the nitty gritty splitting work.\n",
    "    # loops over bonds until bonds get exhausted or bonds are ok to break, whichever comes first. If ok to break, then each\n",
    "    # fragment needs to be checked individually again through the loop\n",
    "    def spf(self, mol, split_id):\n",
    "\n",
    "        bonds = mol.GetBonds()\n",
    "        for i in range(len(bonds)):\n",
    "            if self.okToBreak(bonds[i]):\n",
    "                mol = Chem.FragmentOnBonds(mol, [i])\n",
    "                # Dummy atoms are always added last\n",
    "                n_at = mol.GetNumAtoms()\n",
    "                print('Split ID', split_id)\n",
    "                mol.GetAtomWithIdx(n_at-1).SetAtomicNum(split_id)\n",
    "                mol.GetAtomWithIdx(n_at-2).SetAtomicNum(split_id)\n",
    "                return Chem.rdmolops.GetMolFrags(mol, asMols=True)\n",
    "\n",
    "        # If the molecule could not been split, return original molecule\n",
    "        return [mol]\n",
    "    #get_fragments(fragment_mols)\n",
    "\n",
    "    def retreive_plip_interactions(self, pdb_file):\n",
    "        \"\"\"\n",
    "        Retreives the interactions from PLIP.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdb_file :\n",
    "            The PDB file of the complex. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict :\n",
    "            A dictionary of the binding sites and the interactions.\n",
    "        \"\"\"\n",
    "        protlig = PDBComplex()   #instantiate the loader from PLIP\n",
    "        protlig.load_pdb(pdb_file)   # load the pdb file\n",
    "        for ligand in protlig.ligands:\n",
    "            protlig.characterize_complex(ligand)   # find ligands and analyze interactions\n",
    "        sites = {}\n",
    "        # loop over binding sites\n",
    "        for key, site in sorted(protlig.interaction_sets.items()):\n",
    "            binding_site = BindingSiteReport(site)   # collect data about interactions\n",
    "            # tuples of *_features and *_info will be converted to pandas DataFrame\n",
    "            keys = (\n",
    "                \"hydrophobic\",\n",
    "                \"hbond\",\n",
    "                \"waterbridge\",\n",
    "                \"saltbridge\",\n",
    "                \"pistacking\",\n",
    "                \"pication\",\n",
    "                \"halogen\",\n",
    "                \"metal\"\n",
    "            )\n",
    "        # interactions is a dictionary which contains relevant information for each\n",
    "        # of the possible interactions: hydrophobic, hbond, etc. in the considered\n",
    "        # binding site. Each interaction contains a list with \n",
    "        # 1. the features of that interaction, e.g. for hydrophobic:\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "        # 2. information for each of these features, e.g. for hydrophobic\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "\n",
    "            interactions = {\n",
    "                k: [getattr(binding_site, k + \"_features\")] + getattr(binding_site, k + \"_info\")\n",
    "                for k in keys\n",
    "            }\n",
    "            sites[key] = interactions\n",
    "        return sites\n",
    "\n",
    "    def get_coords_prot(self, RESNR):\n",
    "        ppdb = PandasPdb()\n",
    "        ppdb.read_pdb(f\"{self.pdb.split('.')[0]}_protein.pdb\")\n",
    "        only_protein=ppdb.df['ATOM']\n",
    "        resnr_coords=[]\n",
    "        for i in RESNR:\n",
    "            resnr_coords.append(list(only_protein[only_protein['atom_number']==int(i)][['x_coord', 'y_coord', 'z_coord']].values[0]))\n",
    "        return resnr_coords\n",
    "    \n",
    "    def interaction_df(self, split):\n",
    "\n",
    "        all_interactions_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        # We create the dictionary for the complex of interest:\n",
    "        for idx, s in enumerate(split):\n",
    "\n",
    "            pdb_id=s.split('.')[0]\n",
    "            raw=pdb_id.split('_')[1]\n",
    "            idx_frag=int(pdb_id.split('_')[2])\n",
    "            interactions_by_site = self.retreive_plip_interactions(f\"{pdb_id}.pdb\")\n",
    "\n",
    "            # Let’s see how many binding sites are detected:\n",
    "\n",
    "    #         print(\n",
    "    #             f\"Number of binding sites detected in {pdb_id} : \"\n",
    "    #             f\"{len(interactions_by_site)}\\n\"\n",
    "    #             f\"with {interactions_by_site.keys()}\"\n",
    "    #         )\n",
    "            # In this case, the first binding site containing ligand 03P will be further investigated.\n",
    "            index_of_selected_site = 0\n",
    "            selected_site = list(interactions_by_site.keys())[index_of_selected_site]\n",
    "            #print(selected_site)\n",
    "\n",
    "\n",
    "            valid_types = [\n",
    "                    \"hydrophobic\",\n",
    "                    \"hbond\",\n",
    "                    \"waterbridge\",\n",
    "                    \"saltbridge\",\n",
    "                    \"pistacking\",\n",
    "                    \"pication\",\n",
    "                    \"halogen\",\n",
    "                    \"metal\",\n",
    "                ]\n",
    "\n",
    "            for _type in valid_types:\n",
    "                output_df=self.create_df_from_binding_site(raw, interactions_by_site[selected_site], idx+self.MOL_SPLIT_START, selected_site,\n",
    "                                                      interactions_by_site,\n",
    "                                                      interaction_type=_type)\n",
    "                all_interactions_df=all_interactions_df.append(output_df)\n",
    "        all_interactions_df = all_interactions_df[all_interactions_df['RESNR'].notna()]\n",
    "        all_interactions_df.to_csv(f\"{self.path}/results_plifs/{raw}_plifs_and_properties.csv\", index=False)\n",
    "        return all_interactions_df\n",
    "\n",
    "\n",
    "    # We can construct a pandas.DataFrame for a binding site and particular interaction type.\n",
    "\n",
    "    def create_df_from_binding_site(self, raw, selected_site_interactions, fragment_idx, selected_site, \n",
    "                                    interactions_by_site, interaction_type=\"hbond\"):\n",
    "        \"\"\"\n",
    "        Creates a data frame from a binding site and interaction type.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selected_site_interactions : dict\n",
    "            Precalculated interactions from PLIP for the selected site\n",
    "        interaction_type : str\n",
    "            The interaction type of interest (default set to hydrogen bonding).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame :\n",
    "            DataFrame with information retreived from PLIP.\n",
    "        \"\"\"\n",
    "        # check if interaction type is valid:\n",
    "        valid_types = [\n",
    "            \"hydrophobic\",\n",
    "            \"hbond\",\n",
    "            \"waterbridge\",\n",
    "            \"saltbridge\",\n",
    "            \"pistacking\",\n",
    "            \"pication\",\n",
    "            \"halogen\",\n",
    "            \"metal\",\n",
    "        ]\n",
    "\n",
    "\n",
    "        if interaction_type not in valid_types:\n",
    "            print(\"!!! Wrong interaction type specified. Hbond is chosen by default !!! \\n\")\n",
    "            interaction_type = \"hbond\"\n",
    "\n",
    "        def interaction_values(n):\n",
    "            try:\n",
    "                interactions=interactions_by_site[selected_site][interaction_type]\n",
    "                if type(n) is list:\n",
    "                    return [interactions[1:][x][i] for x in \n",
    "                        range(len(interactions[1:])) for i in n]\n",
    "                else:\n",
    "                    return [interactions[1:][x][n] for x in \n",
    "                        range(len(interactions[1:]))]\n",
    "            except Exception:\n",
    "                return None\n",
    "            \n",
    "        if interactions_by_site[selected_site][interaction_type][1:]:\n",
    "            #print(list(map(interaction_values, self.interaction_slices[interaction_type])), self.column_names)\n",
    "            selected_feats=list(map(interaction_values, self.interaction_slices[interaction_type]))\n",
    "            #print(selected_feats)\n",
    "            try: \n",
    "                if int(selected_feats[4])>int(selected_feats[3]):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3]  \n",
    "            except: \n",
    "                if int(any(selected_feats[4]))>int(any(selected_feats[3])):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3] \n",
    "            df = pd.DataFrame(\n",
    "                # data is stored AFTER the columns names\n",
    "                [selected_feats],\n",
    "                # column names are always the first element - we skipped that in the above - we are gonna use that for naming the df\n",
    "                columns = self.column_names\n",
    "            )\n",
    "\n",
    "            df[\"INTERACTION_TYPE\"]=interaction_type\n",
    "            \n",
    "            try:\n",
    "                checked_coords=self.get_coords_prot(selected_feats[4][0].split(',') if ',' in selected_feats[4][0] \\\n",
    "                                                                   else selected_feats[4])\n",
    "            except:\n",
    "                checked_coords=selected_feats[6]\n",
    "                \n",
    "            df[\"AA_COORDS\"]=[checked_coords]\n",
    "                #[self.get_coords_prot(selected_feats[4].split(','))]\n",
    "            df[\"FRAGMENT_ATOMS_COORDS\"]=[selected_feats[5]]\n",
    "                            #[self.get_coords_lig(selected_feats[3].split(','))]    \n",
    "            df['FRAGMENT_ID']=fragment_idx\n",
    "\n",
    "            # ideally we would like to exclude waters from further processing. Threrfore let us reduce any waterbridge \n",
    "            # interaction to the eucladean distance in order to omit water\n",
    "            \n",
    "            if interaction_type == \"waterbridge\":\n",
    "                df['DIST']=[[np.linalg.norm(x) for x in df['DIST'].to_numpy()]]\n",
    "                \n",
    "            # also deal with one distance value and two coords, this is common in saltbridge interactions:\n",
    "            if len(checked_coords) == len(selected_feats[2])*2:\n",
    "                df['DIST']=[selected_feats[2] + selected_feats[2]]\n",
    "                \n",
    "        else:\n",
    "\n",
    "            df= pd.DataFrame({'RESNR':[None], 'RESTYPE':[None], 'DIST':[None], 'LIG_IDX':[None],'PROT_IDX':[None],\n",
    "                        'INTERACTION_TYPE':[interaction_type], \"AA_COORDS\": [None], \"FRAGMENT_ATOMS_COORDS\":[None],\n",
    "                              'FRAGMENT_ID':[str(fragment_idx)]})\n",
    "\n",
    "\n",
    "\n",
    "        return df\n",
    "    def pdb_2_sdf(self, pdb):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"pdb\", \"sdf\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, pdb)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "\n",
    "\n",
    "        obConversion.WriteFile(mol, f\"{pdb.split('.')[0]}.sdf\")\n",
    "        return f\"{pdb.split('.')[0]}.sdf\"\n",
    "    \n",
    "    def sdf_2_pdb(self, sdf):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"sdf\", \"pdb\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, sdf)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "        obConversion.WriteFile(mol, f\"{sdf.split('.')[0]}.pdb\")\n",
    "        return f\"HETATM_{sdf.split('.')[0]}.pdb\"\n",
    "\n",
    "    def save_bpdb(self, pdb,ppdb, record):  \n",
    "        ppdb.to_pdb(path=f\"{record}_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                    records=[record],\n",
    "                    gz=False, \n",
    "                    append_newline=True)\n",
    "\n",
    "    def get_HOH_pdb(self, pdb):\n",
    "        ppdb = PandasPdb() \n",
    "        ppdb.read_pdb(pdb) \n",
    "        ppdb.df['HETATM']=ppdb.df['HETATM'].loc[ppdb.df['HETATM']['residue_name'].isin(self.values)]\n",
    "        ppdb.to_pdb(path=f\"HOH_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                records=['HETATM'],\n",
    "                gz=False, \n",
    "                append_newline=True)\n",
    "\n",
    "    def keep_relevant_hetatm(self, pdb):\n",
    "        with open(pdb) as f1, open(f\"ATOM_{pdb.split('.')[0].split('_')[0]}.pdb\", 'w') as f2:\n",
    "            for line in f1:\n",
    "                if 'ATOM' in line:\n",
    "                    f2.write(line)\n",
    "                    \n",
    "        self.get_HOH_pdb(pdb)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def fragment_and_plif(self):\n",
    "        path = os.getcwd()\n",
    "        if not os.path.exists('results_plifs'):\n",
    "            os.mkdir(f'{path}/results_plifs')\n",
    "         \n",
    "        raw=str(self.pdb).split('.')[0]\n",
    "        self.keep_relevant_hetatm(f'{raw}_protein.pdb')\n",
    "        self.sdf_2_pdb(f'{raw}_ligand.sdf')\n",
    "        fragment_mols = Chem.SDMolSupplier(str(f'{raw}_ligand.sdf'), removeHs=True, sanitize=False)\n",
    "        try: fragment_mols = Chem.RemoveHs(fragment_mols[0])\n",
    "        except: fragment_mols = AllChem.MolFromPDBFile(f'{raw}_ligand.pdb')\n",
    "        try: output_df = self.interaction_df(self.split_molecule(fragment_mols,raw))\n",
    "        except: output_df = self.interaction_df(self.split_molecule( Chem.MolFromMol2File(f'{raw}_ligand.mol2', sanitize=True, removeHs=True),raw))\n",
    "        os.chdir(f'{path}')\n",
    "        \n",
    "        return output_df.groupby('FRAGMENT_ID')['AA_COORDS', 'FRAGMENT_ATOMS_COORDS','INTERACTION_TYPE','DIST'].agg(list)\n",
    "    \n",
    "\n",
    "def kd_equalizer (value):\n",
    "\n",
    "    if 'mM' in value.split('=')[1]:\n",
    "        return float(value.split('m')[0].split('=')[1]) / 1000\n",
    "    elif 'uM' in value.split('=')[1]:\n",
    "        return float(value.split('u')[0].split('=')[1]) / 1000000\n",
    "    elif 'nM' in value.split('=')[1]:\n",
    "        return float(value.split('n')[0].split('=')[1]) / 1000000000\n",
    "    elif 'pM' in value.split('=')[1]:\n",
    "        return float(value.split('p')[0].split('=')[1]) / 1000000000000\n",
    "    elif 'fM' in value.split('=')[1]:\n",
    "        return float(value.split('f')[0].split('=')[1]) / 1000000000000000\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    os.chdir(f'/groups/cherkasvgrp/share/progressive_docking/hmslati/plif_cnn/')\n",
    "             \n",
    "    train_grids=None\n",
    "    test_grids=None\n",
    "    rotations=9\n",
    "    full_batch=10\n",
    "    features_shape=72\n",
    "    \n",
    "    Feature = Feature_extractor()\n",
    "    \n",
    "    p_directory = os.getcwd()\n",
    "    \n",
    "    general=pd.read_csv('INDEX_general_PL_data.2020', sep=',')\n",
    "    refined=pd.read_csv('INDEX_refined_data.2020', sep=',')\n",
    "    \n",
    "    general=general[general[\"Kd/Ki\"].str.contains('IC|EC|>|<')==False]\n",
    "    refined=refined[refined[\"Kd/Ki\"].str.contains('IC|EC|>|<')==False]\n",
    "\n",
    "    general[\"Kd/Ki\"] = general[\"Kd/Ki\"].str.replace('~','=')\n",
    "    refined[\"Kd/Ki\"] = refined[\"Kd/Ki\"].str.replace('~','=')\n",
    "\n",
    "\n",
    "    general['Kd/Ki']=general['Kd/Ki'].apply(lambda x: kd_equalizer(x))\n",
    "    refined['Kd/Ki']=refined['Kd/Ki'].apply(lambda x: kd_equalizer(x))\n",
    "\n",
    "    merged_PDBBind=general.append(refined) \\\n",
    "                                .sample(frac=1) \\\n",
    "                                .sample(frac=1) \\\n",
    "                                .reset_index(drop=True) \\\n",
    "                                .drop_duplicates(subset='PDB_code', keep=\"first\") \n",
    "\n",
    "\n",
    "    train_df, test_df = train_test_split(merged_PDBBind, test_size=0.1)\n",
    "    \n",
    "    # First training grids: \n",
    "    train_label=[]\n",
    "    \n",
    "    for _ , row in train_df.iterrows():\n",
    "        \n",
    "        pdb_id = row['PDB_code']\n",
    "        print('pdb_id', pdb_id)\n",
    "        \n",
    "        os.chdir(f'general_refined_set/{pdb_id}')\n",
    "        \n",
    "        raw=pdb_id\n",
    "        path = os.getcwd()\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", filePath)\n",
    "                \n",
    "        df_plifSpecs = PLIF(PDB = f'{pdb_id}.pdb').fragment_and_plif()\n",
    "        \n",
    "        train_label.extend([row['Kd/Ki']]*10)\n",
    "        \n",
    "        single_pdb_frags = []\n",
    "        for idx, row in df_plifSpecs.iterrows():\n",
    "    \n",
    "            temp_plifs_prot={}\n",
    "            temp_plifs_frag={}\n",
    "            ## do something with fragment_idx . i.e. open the pdb and do your shit with encoding\\\n",
    "            for aa_atm_coord_list, frag_lig_atm_coord_list, interaction, dist_list in zip (row['AA_COORDS'], \n",
    "                                                                                               row['FRAGMENT_ATOMS_COORDS'],\n",
    "                                                                                               row['INTERACTION_TYPE'],\n",
    "                                                                                               row['DIST']):\n",
    "                # because sometimes salt bridges makes two concurrent connections so it is possible that we have one distance\n",
    "                # for two amino acids or ligand atoms! Encoding by atom is crazy fun\n",
    "                for dist, aa_atm_coord, frag_lig_atm_coord in zip (dist_list, aa_atm_coord_list, \n",
    "                                                                                 frag_lig_atm_coord_list):\n",
    "                    temp_plifs_prot[tuple(aa_atm_coord)]=[interaction,dist]\n",
    "                    temp_plifs_frag[tuple(frag_lig_atm_coord)]=[interaction,dist]\n",
    "\n",
    "\n",
    "            pdb = next(pybel.readfile('pdb',os.path.join(path,'ATOM_' + pdb_id + '.pdb')))\n",
    "            ligand = next(pybel.readfile('pdb',os.path.join(path, pdb_id + f'_{str(idx)}'+'.pdb')))\n",
    "            single_pdb_frags.append((pdb,ligand,temp_plifs_prot,temp_plifs_frag))  \n",
    "            \n",
    "        grid=np.zeros((full_batch,200,200,200,features_shape),dtype=np.float32)\n",
    "        \n",
    "        for idx, mols in enumerate(single_pdb_frags):\n",
    "            coords1, features1 = Feature.get_features(mols[0],mols[2],1)\n",
    "            coords2, features2 = Feature.get_features(mols[1],mols[3],0)\n",
    "\n",
    "            # get the center point of protein\n",
    "            center=(np.max(coords2,axis=0)+np.min(coords2,axis=0))/2\n",
    "            coords=np.concatenate([coords1,coords2],axis = 0)\n",
    "            features=np.concatenate([features1,features2],axis = 0)\n",
    "            assert len(coords) == len(features)\n",
    "            # zero the coordinates \n",
    "            coords = coords-center\n",
    "            grid=Feature.grid(grid,coords,features,idx, rotation_bool=True)\n",
    "        \n",
    "        if train_grids is None:\n",
    "            train_grids = grid\n",
    "        else:\n",
    "            train_grids = np.concatenate([train_grids,grid],axis = 0)\n",
    "        print(train_grids.shape)\n",
    "        \n",
    "        raw=pdb_id\n",
    "        path = os.getcwd()\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", filePath)\n",
    "                \n",
    "        os.chdir(p_directory)\n",
    "        \n",
    "    \n",
    "    with open('train_grids.pkl','wb') as f:\n",
    "        pickle.dump(train_grids, f)\n",
    "\n",
    "    # Second testing grids: \n",
    "    test_label=[]\n",
    "    \n",
    "    for _ , row in test_df.iterrows():\n",
    "        \n",
    "        pdb_id = row['PDB_code']\n",
    "        print('pdb_id', pdb_id)\n",
    "        \n",
    "        os.chdir(f'general_refined_set/{pdb_id}')\n",
    "        \n",
    "        raw=pdb_id\n",
    "        path = os.getcwd()\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", filePath)\n",
    "                \n",
    "        df_plifSpecs = PLIF(PDB = f'{pdb_id}.pdb').fragment_and_plif()\n",
    "        \n",
    "        test_label.extend([row['Kd/Ki']]*10)\n",
    "        \n",
    "        single_pdb_frags = []\n",
    "        for idx, row in df_plifSpecs.iterrows():\n",
    "    \n",
    "            temp_plifs_prot={}\n",
    "            temp_plifs_frag={}\n",
    "            ## do something with fragment_idx . i.e. open the pdb and do your shit with encoding\\\n",
    "            for aa_atm_coord_list, frag_lig_atm_coord_list, interaction, dist_list in zip (row['AA_COORDS'], \n",
    "                                                                                               row['FRAGMENT_ATOMS_COORDS'],\n",
    "                                                                                               row['INTERACTION_TYPE'],\n",
    "                                                                                               row['DIST']):\n",
    "                # because sometimes salt bridges makes two concurrent connections so it is possible that we have one distance\n",
    "                # for two amino acids or ligand atoms! Encoding by atom is crazy fun\n",
    "                for dist, aa_atm_coord, frag_lig_atm_coord in zip (dist_list, aa_atm_coord_list, \n",
    "                                                                                 frag_lig_atm_coord_list):\n",
    "                    temp_plifs_prot[tuple(aa_atm_coord)]=[interaction,dist]\n",
    "                    temp_plifs_frag[tuple(frag_lig_atm_coord)]=[interaction,dist]\n",
    "\n",
    "\n",
    "            pdb = next(pybel.readfile('pdb',os.path.join(path,'ATOM_' + pdb_id + '.pdb')))\n",
    "            ligand = next(pybel.readfile('pdb',os.path.join(path, pdb_id + f'_{str(idx)}'+'.pdb')))\n",
    "            single_pdb_frags.append((pdb,ligand,temp_plifs_prot,temp_plifs_frag))  \n",
    "            \n",
    "        grid=np.zeros((1,200,200,200,features_shape),dtype=np.float32)\n",
    "        \n",
    "        for idx, mols in enumerate(single_pdb_frags):\n",
    "            coords1, features1 = Feature.get_features(mols[0],mols[2],1)\n",
    "            coords2, features2 = Feature.get_features(mols[1],mols[3],0)\n",
    "\n",
    "            # get the center point of protein\n",
    "            center=(np.max(coords2,axis=0)+np.min(coords2,axis=0))/2\n",
    "            coords=np.concatenate([coords1,coords2],axis = 0)\n",
    "            features=np.concatenate([features1,features2],axis = 0)\n",
    "            assert len(coords) == len(features)\n",
    "            # zero the coordinates \n",
    "            coords = coords-center\n",
    "            grid=Feature.grid(grid,coords,features,idx, rotation_bool=False)\n",
    "        \n",
    "        if test_grids is None:\n",
    "            test_grids = grid\n",
    "        else:\n",
    "            test_grids = np.concatenate([train_grids,grid],axis = 0)\n",
    "        print(train_grids.shape)\n",
    "        \n",
    "        raw=pdb_id\n",
    "        path = os.getcwd()\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", filePath)\n",
    "                \n",
    "        os.chdir(p_directory)\n",
    "        \n",
    "    \n",
    "    with open('test_grids.pkl','wb') as f:\n",
    "        pickle.dump(test_grids, f)\n",
    "        \n",
    "    \n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from openbabel import pybel\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import openbabel\n",
    "import numpy as np\n",
    "from plip.structure.preparation import PDBComplex\n",
    "from plip.exchange.report import BindingSiteReport\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from biopandas.pdb import PandasPdb\n",
    "from Bio.PDB.SASA import ShrakeRupley\n",
    "from Bio.PDB import PDBParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# PLEASE READ -> 45次实验分别进行10倍交叉验证，取平均\n",
    "\n",
    "#Converts the protein-ligand complexes into 4D tensor. \n",
    "class Feature_extractor():\n",
    "    def __init__(self):\n",
    "        self.atom_codes = {}\n",
    "        #'others' includs metal atoms and B atom. There are no B atoms on training and test sets. \n",
    "        # 55 to 63 will be reserved to PLIF features as follows:\n",
    "        # 55: hydrophobic\n",
    "        # 56: hbond\n",
    "        # 57: waterbridge\n",
    "        # 58: saltbridge\n",
    "        # 59: pistacking\n",
    "        # 60: pication\n",
    "        # 61: halogen\n",
    "        # 62: metal\n",
    "        # 63: Distances \n",
    "        \n",
    "        # others = ([3,4,5,11,12,13]+list(range(19,32))+list(range(37,51))+list(range(55,84)))\n",
    "        plif_specs=list(range(55,64))\n",
    "        #C and N atoms can be hybridized in three ways and S atom can be hybridized in two ways here. \n",
    "        #Hydrogen atom is also considered for feature extraction. I think phosphor atom has 3 or 5 as hyb states but \n",
    "        # in biological system its usually the same recurrent phosphate even in most small molecules so safe to assume one\n",
    "        # hybridization state for this purpose. \n",
    "        atom_types = [1,(6,1),(6,2),(6,3),(7,1),(7,2),(7,3),8,15,(16,2),(16,3),\n",
    "                      34,9,17,35,53,11,12,13,14,5,19,20,25,29,28,30]+plif_specs\n",
    "      \n",
    "        for i, j in enumerate(atom_types):\n",
    "            if type(j) is list:\n",
    "                for k in j:\n",
    "                    self.atom_codes[k] = i\n",
    "                \n",
    "            else:\n",
    "                self.atom_codes[j] = i              \n",
    "        \n",
    "        self.sum_atom_types = len(atom_types)\n",
    "        \n",
    "    #Onehot encoding of each atom. The atoms in protein or ligand are treated separately.\n",
    "    def encode(self, atomic_num, orig_coords, plifs, molprotein):\n",
    "        encoding = np.zeros(self.sum_atom_types*2)\n",
    "        if molprotein == 1:\n",
    "            encoding[self.atom_codes[atomic_num]] = 1.0\n",
    "            for coord, plif_feats in plifs.items():\n",
    "                if [round(item) for item in coord] == [round(item) for item in orig_coords]:\n",
    "                    encoding[self.atom_codes[55]] = 1.0 if plifs[coord][0] == 'hydrophobic' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[56]] = 1.0 if plifs[coord][0] == 'hbond' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[57]] = 1.0 if plifs[coord][0] == 'waterbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[58]] = 1.0 if plifs[coord][0] == 'saltbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[59]] = 1.0 if plifs[coord][0] == 'pistacking' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[60]] = 1.0 if plifs[coord][0] == 'pication' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[61]] = 1.0 if plifs[coord][0] == 'halogen' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[62]] = 1.0 if plifs[coord][0] == 'metal' \\\n",
    "                    else 0.0\n",
    "                    \n",
    "                    #distance\n",
    "                    encoding[self.atom_codes[63]] = plifs[coord][1]\n",
    "                    \n",
    "\n",
    "                \n",
    "        else:\n",
    "            encoding[self.sum_atom_types+self.atom_codes[atomic_num]] = 1.0\n",
    "            for coord, plif_feats in plifs.items():\n",
    "                if [round(item) for item in coord] == [round(item) for item in orig_coords]:\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[55]] = 1.0 if plifs[coord][0] == 'hydrophobic' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[56]] = 1.0 if plifs[coord][0] == 'hbond' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[57]] = 1.0 if plifs[coord][0] == 'waterbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[58]] = 1.0 if plifs[coord][0] == 'saltbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[59]] = 1.0 if plifs[coord][0] == 'pistacking' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[60]] = 1.0 if plifs[coord][0] == 'pication' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[61]] = 1.0 if plifs[coord][0] == 'halogen' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[62]] = 1.0 if plifs[coord][0] == 'metal' \\\n",
    "                    else 0.0\n",
    "                    \n",
    "                    #distance\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[63]] = plifs[coord][1]\n",
    "\n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    #Get atom coords and atom features from the complexes.   \n",
    "    def get_features(self, molecule, plifs, molprotein):\n",
    "        coords = []\n",
    "        features = []\n",
    "            \n",
    "        for atom in molecule:\n",
    "            coords.append(atom.coords)\n",
    "            if atom.atomicnum in [6,7,16]:\n",
    "                atomicnum = (atom.atomicnum,atom.hyb)\n",
    "                features.append(self.encode(atomicnum,atom.coords,plifs,molprotein))\n",
    "            else:\n",
    "                features.append(self.encode(atom.atomicnum,atom.coords,plifs,molprotein))\n",
    "        \n",
    "        coords = np.array(coords, dtype=np.float32)\n",
    "        features = np.array(features, dtype=np.float32)\n",
    "\n",
    "        return coords, features\n",
    "     \n",
    "    #Define the rotation matrixs of 3D stuctures.\n",
    "    def rotation_matrix(self, t, roller):\n",
    "        if roller==0:\n",
    "            return np.array([[1,0,0],[0,np.cos(t),np.sin(t)],[0,-np.sin(t),np.cos(t)]])\n",
    "        elif roller==1:\n",
    "            return np.array([[np.cos(t),0,-np.sin(t)],[0,1,0],[np.sin(t),0,np.cos(t)]])\n",
    "        elif roller==2:\n",
    "            return np.array([[np.cos(t),np.sin(t),0],[-np.sin(t),np.cos(t),0],[0,0,1]])\n",
    "\n",
    "    #Generate 3d grid or 4d tensor. Each grid represents a voxel. Each voxel represents the atom in it by onehot encoding of atomic type.\n",
    "    #Each complex in train set is rotated 9 times for data amplification.\n",
    "    #The complexes in core set are not rotated. \n",
    "    #The default resolution is 20*20*20.\n",
    "    def grid(self,grid, coords, features, frag_idx, resolution=1.0, max_dist=10.0,  rotation_bool=True, max_frag=10, rotations=9):\n",
    "        assert coords.shape[1] == 3\n",
    "        assert coords.shape[0] == features.shape[0]  \n",
    "\n",
    "        slider=frag_idx*20\n",
    "\n",
    "        x=y=z=np.array(range(-10,10),dtype=np.float32)+0.5\n",
    "        u=0\n",
    "        for i in range(len(coords)):\n",
    "            coord=coords[i]\n",
    "            # add/subtract 10 from the center\n",
    "            tmpx=abs(coord[0]-x)\n",
    "            tmpy=abs(coord[1]-y)\n",
    "            tmpz=abs(coord[2]-z)\n",
    "\n",
    "            if np.max(tmpx)<=19.5 and np.max(tmpy)<=19.5 and np.max(tmpz) <=19.5:\n",
    "                u+=1\n",
    "                # get the position of the closest point to coordinate which is found inside the grid\n",
    "                # append the features unto that slice\n",
    "                grid[0,slider+np.argmin(tmpx),slider+np.argmin(tmpy),slider+np.argmin(tmpz)] += features[i]\n",
    "                \n",
    "        if rotation_bool:\n",
    "            for rotation_idx in range(rotations):\n",
    "                theta = random.uniform(np.pi/18,np.pi/2)\n",
    "                roller = random.randrange(3)\n",
    "                coords = np.dot(coords, self.rotation_matrix(theta,roller))\n",
    "                for i in range(len(coords)):\n",
    "                    coord=coords[i]\n",
    "                    tmpx=abs(coord[0]-x)\n",
    "                    tmpy=abs(coord[1]-y)\n",
    "                    tmpz=abs(coord[2]-z)\n",
    "                    if np.max(tmpx)<=19.5 and np.max(tmpy)<=19.5 and np.max(tmpz) <=19.5:\n",
    "                        grid[rotation_idx+1,slider+np.argmin(tmpx),slider+np.argmin(tmpy),slider+np.argmin(tmpz)] += features[i]\n",
    "\n",
    "        return grid\n",
    "    \n",
    "class PLIF:\n",
    "    def __init__(self, PDB: str, MOL_SPLIT_START: int = 70, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(PLIF,self).__init__()\n",
    "        \n",
    "        self.MOL_SPLIT_START=MOL_SPLIT_START\n",
    "        self.pdb=PDB\n",
    "        self.records=['ATOM']\n",
    "        self.values=['HOH','CL','MG','ZN','MN','CA']\n",
    "        self.ions=['CL','MG','ZN','MN','CA']\n",
    "        self.interaction_slices={\"hydrophobic\":[0,1,6,7,8,9,10],\n",
    "            \"hbond\":[0,1,7,11,13,15,16],\n",
    "            \"waterbridge\":[0,1,[6,7],11,13,16,17],\n",
    "            \"saltbridge\":[0,1,7,10,3,11,12],\n",
    "            \"pistacking\":[0,1,7,11,6,12,13],\n",
    "            \"pication\":[0,1,7,11,3,12,13],\n",
    "            \"halogen\":[0,1,7,10,12,14,15],\n",
    "            \"metal\":[0,1,11,8,6,17,16]} \n",
    "\n",
    "        self.column_names = ['RESNR', 'RESTYPE', 'DIST', 'LIG_IDX','PROT_IDX','FRAGMENT_ATOMS_COORDS', 'AA_COORDS']\n",
    "        self.path = os.getcwd()\n",
    "\n",
    "\n",
    "    def okToBreak(self, bond):\n",
    "        \"\"\"\n",
    "        Here we apply a bunch of rules to judge if the bond is OK to break.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bond :\n",
    "            RDkit MOL object\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Boolean :\n",
    "            OK or not to break.\n",
    "        \"\"\"\n",
    "        # See if the bond is in Ring (don't break that)\n",
    "        if bond.IsInRing():\n",
    "            return False\n",
    "        # We OK only single bonds to break\n",
    "        if bond.GetBondType() != Chem.rdchem.BondType.SINGLE:\n",
    "            return False\n",
    "\n",
    "        # Get the beginning atom of the bond\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        # Get the ending atom of the bond\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        # What kind of neighbors does these end and begenning atoms have? We need a family of no less than 5!\n",
    "        neighbor_end=list(end_atom.GetNeighbors())\n",
    "        neighbor_begin=list(begin_atom.GetNeighbors())\n",
    "        if (len(neighbor_end) + len(neighbor_begin)) <5:\n",
    "            return False\n",
    "        #for atm in neighbor_end:\n",
    "            #print(atm.GetAtomicNum())\n",
    "        #print(begin_atom.GetAtomicNum(), end_atom.GetAtomicNum(), MOL_SPLIT_START)\n",
    "        \n",
    "        # Now check if end or begenning atoms are in ring (we dont wanna bother those)\n",
    "        if not(begin_atom.IsInRing() or end_atom.IsInRing()):\n",
    "            return False\n",
    "        elif begin_atom.GetAtomicNum() >= self.MOL_SPLIT_START or \\\n",
    "                end_atom.GetAtomicNum() >= self.MOL_SPLIT_START:\n",
    "            return False\n",
    "        elif end_atom.GetAtomicNum() == 1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def undo_id_label (self, frag, split_id):\n",
    "        # I am trying to restore Hydrogens where the break happened\n",
    "        for i, atom in enumerate(frag.GetAtoms()):\n",
    "            if atom.GetAtomicNum() >= split_id:\n",
    "                atom.SetAtomicNum(1)\n",
    "\n",
    "        return frag\n",
    "\n",
    "    # Divide a molecule into fragments\n",
    "    def split_molecule(self, mol, pdb):\n",
    "\n",
    "        split_id = self.MOL_SPLIT_START\n",
    "\n",
    "        res = []\n",
    "        res_no_id=[]\n",
    "\n",
    "        to_check = [mol]\n",
    "        while len(to_check) > 0:\n",
    "            ms = self.spf(to_check.pop(), split_id)\n",
    "            if len(ms) == 1:\n",
    "                res += ms\n",
    "            else:\n",
    "                to_check += ms\n",
    "                split_id += 1\n",
    "        for frag in res:\n",
    "            res_no_id.append(self.undo_id_label(frag, self.MOL_SPLIT_START))\n",
    "\n",
    "        res_pdb_frags=[]\n",
    "\n",
    "        for idx, frag in enumerate(res_no_id):\n",
    "            w = Chem.PDBWriter(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "            w.write(frag)\n",
    "            w.close()\n",
    "            \n",
    "            unwanted_entries= ['CONECT', 'END']            \n",
    "            with open(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as oldfile, open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as newfile:\n",
    "                for line in oldfile:\n",
    "                    if not any(unwanted_entry in line for unwanted_entry in unwanted_entries):\n",
    "                        newfile.write(line)\n",
    "\n",
    "                    \n",
    "            data = data2 = \"\"\n",
    "\n",
    "            # Reading data from file1\n",
    "            with open(f\"ATOM_{pdb}.pdb\") as fp:\n",
    "                data = fp.read()\n",
    "\n",
    "            # Reading data from file2\n",
    "\n",
    "            with open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as fp:\n",
    "                data2 = fp.read()\n",
    "            \n",
    "            # Merging 2 files\n",
    "            # To add the data of file2\n",
    "            # from next line\n",
    "            #data += \"\\n\"\n",
    "            data += data2\n",
    "            \n",
    "            with open(f\"HOH_{pdb}.pdb\") as fp:\n",
    "                data3 = fp.read()\n",
    "            data += data3\n",
    "\n",
    "            with open (f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as fp:\n",
    "                fp.write(data)\n",
    "            res_pdb_frags.append(f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "        return res_pdb_frags #create_chain(res)\n",
    "\n",
    "\n",
    "    # Function for doing all the nitty gritty splitting work.\n",
    "    # loops over bonds until bonds get exhausted or bonds are ok to break, whichever comes first. If ok to break, then each\n",
    "    # fragment needs to be checked individually again through the loop\n",
    "    def spf(self, mol, split_id):\n",
    "\n",
    "        bonds = mol.GetBonds()\n",
    "        for i in range(len(bonds)):\n",
    "            if self.okToBreak(bonds[i]):\n",
    "                mol = Chem.FragmentOnBonds(mol, [i])\n",
    "                # Dummy atoms are always added last\n",
    "                n_at = mol.GetNumAtoms()\n",
    "                print('Split ID', split_id)\n",
    "                mol.GetAtomWithIdx(n_at-1).SetAtomicNum(split_id)\n",
    "                mol.GetAtomWithIdx(n_at-2).SetAtomicNum(split_id)\n",
    "                return Chem.rdmolops.GetMolFrags(mol, asMols=True)\n",
    "\n",
    "        # If the molecule could not been split, return original molecule\n",
    "        return [mol]\n",
    "    #get_fragments(fragment_mols)\n",
    "\n",
    "    def retreive_plip_interactions(self, pdb_file):\n",
    "        \"\"\"\n",
    "        Retreives the interactions from PLIP.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdb_file :\n",
    "            The PDB file of the complex. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict :\n",
    "            A dictionary of the binding sites and the interactions.\n",
    "        \"\"\"\n",
    "        protlig = PDBComplex()   #instantiate the loader from PLIP\n",
    "        protlig.load_pdb(pdb_file)   # load the pdb file\n",
    "        for ligand in protlig.ligands:\n",
    "            protlig.characterize_complex(ligand)   # find ligands and analyze interactions\n",
    "        sites = {}\n",
    "        # loop over binding sites\n",
    "        for key, site in sorted(protlig.interaction_sets.items()):\n",
    "            binding_site = BindingSiteReport(site)   # collect data about interactions\n",
    "            # tuples of *_features and *_info will be converted to pandas DataFrame\n",
    "            keys = (\n",
    "                \"hydrophobic\",\n",
    "                \"hbond\",\n",
    "                \"waterbridge\",\n",
    "                \"saltbridge\",\n",
    "                \"pistacking\",\n",
    "                \"pication\",\n",
    "                \"halogen\",\n",
    "                \"metal\"\n",
    "            )\n",
    "        # interactions is a dictionary which contains relevant information for each\n",
    "        # of the possible interactions: hydrophobic, hbond, etc. in the considered\n",
    "        # binding site. Each interaction contains a list with \n",
    "        # 1. the features of that interaction, e.g. for hydrophobic:\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "        # 2. information for each of these features, e.g. for hydrophobic\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "\n",
    "            interactions = {\n",
    "                k: [getattr(binding_site, k + \"_features\")] + getattr(binding_site, k + \"_info\")\n",
    "                for k in keys\n",
    "            }\n",
    "            sites[key] = interactions\n",
    "        return sites\n",
    "\n",
    "    def get_coords_prot(self, RESNR):\n",
    "        ppdb = PandasPdb()\n",
    "        ppdb.read_pdb(f\"{self.pdb.split('.')[0]}_protein.pdb\")\n",
    "        only_protein=ppdb.df['ATOM']\n",
    "        resnr_coords=[]\n",
    "        for i in RESNR:\n",
    "            resnr_coords.append(list(only_protein[only_protein['atom_number']==int(i)][['x_coord', 'y_coord', 'z_coord']].values[0]))\n",
    "        return resnr_coords\n",
    "    \n",
    "    def interaction_df(self, split):\n",
    "\n",
    "        all_interactions_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        # We create the dictionary for the complex of interest:\n",
    "        for idx, s in enumerate(split):\n",
    "\n",
    "            pdb_id=s.split('.')[0]\n",
    "            raw=pdb_id.split('_')[1]\n",
    "            idx_frag=int(pdb_id.split('_')[2])\n",
    "            interactions_by_site = self.retreive_plip_interactions(f\"{pdb_id}.pdb\")\n",
    "\n",
    "            # Let’s see how many binding sites are detected:\n",
    "\n",
    "    #         print(\n",
    "    #             f\"Number of binding sites detected in {pdb_id} : \"\n",
    "    #             f\"{len(interactions_by_site)}\\n\"\n",
    "    #             f\"with {interactions_by_site.keys()}\"\n",
    "    #         )\n",
    "            # In this case, the first binding site containing ligand 03P will be further investigated.\n",
    "            index_of_selected_site = 0\n",
    "            selected_site = list(interactions_by_site.keys())[index_of_selected_site]\n",
    "            #print(selected_site)\n",
    "\n",
    "\n",
    "            valid_types = [\n",
    "                    \"hydrophobic\",\n",
    "                    \"hbond\",\n",
    "                    \"waterbridge\",\n",
    "                    \"saltbridge\",\n",
    "                    \"pistacking\",\n",
    "                    \"pication\",\n",
    "                    \"halogen\",\n",
    "                    \"metal\",\n",
    "                ]\n",
    "\n",
    "            for _type in valid_types:\n",
    "                output_df=self.create_df_from_binding_site(raw, interactions_by_site[selected_site], idx+self.MOL_SPLIT_START, selected_site,\n",
    "                                                      interactions_by_site,\n",
    "                                                      interaction_type=_type)\n",
    "                all_interactions_df=all_interactions_df.append(output_df)\n",
    "        all_interactions_df = all_interactions_df[all_interactions_df['RESNR'].notna()]\n",
    "        all_interactions_df.to_csv(f\"{self.path}/results_plifs/{raw}_plifs_and_properties.csv\", index=False)\n",
    "        return all_interactions_df\n",
    "\n",
    "\n",
    "    # We can construct a pandas.DataFrame for a binding site and particular interaction type.\n",
    "\n",
    "    def create_df_from_binding_site(self, raw, selected_site_interactions, fragment_idx, selected_site, \n",
    "                                    interactions_by_site, interaction_type=\"hbond\"):\n",
    "        \"\"\"\n",
    "        Creates a data frame from a binding site and interaction type.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selected_site_interactions : dict\n",
    "            Precalculated interactions from PLIP for the selected site\n",
    "        interaction_type : str\n",
    "            The interaction type of interest (default set to hydrogen bonding).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame :\n",
    "            DataFrame with information retreived from PLIP.\n",
    "        \"\"\"\n",
    "        # check if interaction type is valid:\n",
    "        valid_types = [\n",
    "            \"hydrophobic\",\n",
    "            \"hbond\",\n",
    "            \"waterbridge\",\n",
    "            \"saltbridge\",\n",
    "            \"pistacking\",\n",
    "            \"pication\",\n",
    "            \"halogen\",\n",
    "            \"metal\",\n",
    "        ]\n",
    "\n",
    "\n",
    "        if interaction_type not in valid_types:\n",
    "            print(\"!!! Wrong interaction type specified. Hbond is chosen by default !!! \\n\")\n",
    "            interaction_type = \"hbond\"\n",
    "\n",
    "        def interaction_values(n):\n",
    "            try:\n",
    "                interactions=interactions_by_site[selected_site][interaction_type]\n",
    "                if type(n) is list:\n",
    "                    return [interactions[1:][x][i] for x in \n",
    "                        range(len(interactions[1:])) for i in n]\n",
    "                else:\n",
    "                    return [interactions[1:][x][n] for x in \n",
    "                        range(len(interactions[1:]))]\n",
    "            except Exception:\n",
    "                return None\n",
    "            \n",
    "        if interactions_by_site[selected_site][interaction_type][1:]:\n",
    "            #print(list(map(interaction_values, self.interaction_slices[interaction_type])), self.column_names)\n",
    "            selected_feats=list(map(interaction_values, self.interaction_slices[interaction_type]))\n",
    "            #print(selected_feats)\n",
    "            try: \n",
    "                if int(selected_feats[4])>int(selected_feats[3]):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3]  \n",
    "            except: \n",
    "                if int(any(selected_feats[4]))>int(any(selected_feats[3])):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3] \n",
    "            df = pd.DataFrame(\n",
    "                # data is stored AFTER the columns names\n",
    "                [selected_feats],\n",
    "                # column names are always the first element - we skipped that in the above - we are gonna use that for naming the df\n",
    "                columns = self.column_names\n",
    "            )\n",
    "\n",
    "            df[\"INTERACTION_TYPE\"]=interaction_type\n",
    "            \n",
    "            try:\n",
    "                checked_coords=self.get_coords_prot(selected_feats[4][0].split(',') if ',' in selected_feats[4][0] \\\n",
    "                                                                   else selected_feats[4])\n",
    "            except:\n",
    "                checked_coords=selected_feats[6]\n",
    "                \n",
    "            df[\"AA_COORDS\"]=[checked_coords]\n",
    "                #[self.get_coords_prot(selected_feats[4].split(','))]\n",
    "            df[\"FRAGMENT_ATOMS_COORDS\"]=[selected_feats[5]]\n",
    "                            #[self.get_coords_lig(selected_feats[3].split(','))]    \n",
    "            df['FRAGMENT_ID']=fragment_idx\n",
    "\n",
    "            # ideally we would like to exclude waters from further processing. Threrfore let us reduce any waterbridge \n",
    "            # interaction to the eucladean distance in order to omit water\n",
    "            \n",
    "            if interaction_type == \"waterbridge\":\n",
    "                df['DIST']=[[np.linalg.norm(x) for x in df['DIST'].to_numpy()]]\n",
    "                \n",
    "            # also deal with one distance value and two coords, this is common in saltbridge interactions:\n",
    "            if len(checked_coords) == len(selected_feats[2])*2:\n",
    "                df['DIST']=[selected_feats[2] + selected_feats[2]]\n",
    "                \n",
    "        else:\n",
    "\n",
    "            df= pd.DataFrame({'RESNR':[None], 'RESTYPE':[None], 'DIST':[None], 'LIG_IDX':[None],'PROT_IDX':[None],\n",
    "                        'INTERACTION_TYPE':[interaction_type], \"AA_COORDS\": [None], \"FRAGMENT_ATOMS_COORDS\":[None],\n",
    "                              'FRAGMENT_ID':[str(fragment_idx)]})\n",
    "\n",
    "\n",
    "\n",
    "        return df\n",
    "    def pdb_2_sdf(self, pdb):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"pdb\", \"sdf\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, pdb)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "\n",
    "\n",
    "        obConversion.WriteFile(mol, f\"{pdb.split('.')[0]}.sdf\")\n",
    "        return f\"{pdb.split('.')[0]}.sdf\"\n",
    "    \n",
    "    def sdf_2_pdb(self, sdf):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"sdf\", \"pdb\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, sdf)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "        obConversion.WriteFile(mol, f\"{sdf.split('.')[0]}.pdb\")\n",
    "        return f\"HETATM_{sdf.split('.')[0]}.pdb\"\n",
    "\n",
    "    def save_bpdb(self, pdb,ppdb, record):  \n",
    "        ppdb.to_pdb(path=f\"{record}_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                    records=[record],\n",
    "                    gz=False, \n",
    "                    append_newline=True)\n",
    "\n",
    "    def get_HOH_pdb(self, pdb):\n",
    "        ppdb = PandasPdb() \n",
    "        ppdb.read_pdb(pdb) \n",
    "        ppdb.df['HETATM']=ppdb.df['HETATM'].loc[ppdb.df['HETATM']['residue_name'].isin(self.values)]\n",
    "        ppdb.to_pdb(path=f\"HOH_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                records=['HETATM'],\n",
    "                gz=False, \n",
    "                append_newline=True)\n",
    "\n",
    "    def keep_relevant_hetatm(self, pdb):\n",
    "        with open(pdb) as f1, open(f\"ATOM_{pdb.split('.')[0].split('_')[0]}.pdb\", 'w') as f2:\n",
    "            for line in f1:\n",
    "                if 'ATOM' in line:\n",
    "                    f2.write(line)\n",
    "        try: self.get_HOH_pdb(pdb)\n",
    "        except:\n",
    "            with open(pdb) as f1, open(f\"HOH_{pdb.split('.')[0].split('_')[0]}.pdb\", 'w') as f2:\n",
    "                for line in f1:\n",
    "                    if ('HETATM' in line) and any(ion in line for ion in self.ions):\n",
    "                        f2.write(line)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def fragment_and_plif(self):\n",
    "        path = os.getcwd()\n",
    "        if not os.path.exists('results_plifs'):\n",
    "            os.mkdir(f'{path}/results_plifs')\n",
    "         \n",
    "        raw=str(self.pdb).split('.')[0]\n",
    "        self.keep_relevant_hetatm(f'{raw}_protein.pdb')\n",
    "        self.sdf_2_pdb(f'{raw}_ligand.sdf')\n",
    "        fragment_mols = Chem.SDMolSupplier(str(f'{raw}_ligand.sdf'), removeHs=True, sanitize=False)\n",
    "        try: fragment_mols = Chem.RemoveHs(fragment_mols[0])\n",
    "        except: fragment_mols = AllChem.MolFromPDBFile(f'{raw}_ligand.pdb')\n",
    "        try: output_df = self.interaction_df(self.split_molecule(fragment_mols,raw))\n",
    "        except: output_df = self.interaction_df(self.split_molecule( Chem.MolFromMol2File(f'{raw}_ligand.mol2', sanitize=True, removeHs=True),raw))\n",
    "        os.chdir(f'{path}')\n",
    "        \n",
    "        return output_df.groupby('FRAGMENT_ID')['AA_COORDS', 'FRAGMENT_ATOMS_COORDS','INTERACTION_TYPE','DIST'].agg(list)\n",
    "    \n",
    "\n",
    "def kd_equalizer (value):\n",
    "\n",
    "    if 'mM' in value.split('=')[1]:\n",
    "        return float(value.split('m')[0].split('=')[1]) / 1000\n",
    "    elif 'uM' in value.split('=')[1]:\n",
    "        return float(value.split('u')[0].split('=')[1]) / 1000000\n",
    "    elif 'nM' in value.split('=')[1]:\n",
    "        return float(value.split('n')[0].split('=')[1]) / 1000000000\n",
    "    elif 'pM' in value.split('=')[1]:\n",
    "        return float(value.split('p')[0].split('=')[1]) / 1000000000000\n",
    "    elif 'fM' in value.split('=')[1]:\n",
    "        return float(value.split('f')[0].split('=')[1]) / 1000000000000000\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    os.chdir(f'/groups/cherkasvgrp/share/progressive_docking/hmslati/plif_cnn/')\n",
    "             \n",
    "    train_grids=None\n",
    "    test_grids=None\n",
    "    rotations=9\n",
    "    full_batch=10\n",
    "    features_shape=72\n",
    "    \n",
    "    Feature = Feature_extractor()\n",
    "    \n",
    "    p_directory = os.getcwd()\n",
    "    \n",
    "    general=pd.read_csv('INDEX_general_PL_data.2020', sep=',')\n",
    "    refined=pd.read_csv('INDEX_refined_data.2020', sep=',')\n",
    "    \n",
    "    general=general[general[\"Kd/Ki\"].str.contains('IC|EC|>|<')==False]\n",
    "    refined=refined[refined[\"Kd/Ki\"].str.contains('IC|EC|>|<')==False]\n",
    "\n",
    "    general[\"Kd/Ki\"] = general[\"Kd/Ki\"].str.replace('~','=')\n",
    "    refined[\"Kd/Ki\"] = refined[\"Kd/Ki\"].str.replace('~','=')\n",
    "\n",
    "\n",
    "    general['Kd/Ki']=general['Kd/Ki'].apply(lambda x: kd_equalizer(x))\n",
    "    refined['Kd/Ki']=refined['Kd/Ki'].apply(lambda x: kd_equalizer(x))\n",
    "\n",
    "    merged_PDBBind=general.append(refined) \\\n",
    "                                .sample(frac=1) \\\n",
    "                                .sample(frac=1) \\\n",
    "                                .reset_index(drop=True) \\\n",
    "                                .drop_duplicates(subset='PDB_code', keep=\"first\") \n",
    "\n",
    "\n",
    "    train_df, test_df = train_test_split(merged_PDBBind, test_size=0.1)\n",
    "    \n",
    "    # First training grids: \n",
    "    train_label=[]\n",
    "    \n",
    "    for _ , row in train_df.iterrows():\n",
    "        \n",
    "        pdb_id = row['PDB_code']\n",
    "        print('pdb_id', pdb_id)\n",
    "        \n",
    "        os.chdir(f'general_refined_set/{pdb_id}')\n",
    "        \n",
    "        raw=pdb_id\n",
    "        path = os.getcwd()\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", filePath)\n",
    "                \n",
    "        df_plifSpecs = PLIF(PDB = f'{pdb_id}.pdb').fragment_and_plif()\n",
    "        \n",
    "        train_label.extend([row['Kd/Ki']]*10)\n",
    "        \n",
    "        single_pdb_frags = []\n",
    "        for idx, row in df_plifSpecs.iterrows():\n",
    "    \n",
    "            temp_plifs_prot={}\n",
    "            temp_plifs_frag={}\n",
    "            ## do something with fragment_idx . i.e. open the pdb and do your shit with encoding\\\n",
    "            for aa_atm_coord_list, frag_lig_atm_coord_list, interaction, dist_list in zip (row['AA_COORDS'], \n",
    "                                                                                               row['FRAGMENT_ATOMS_COORDS'],\n",
    "                                                                                               row['INTERACTION_TYPE'],\n",
    "                                                                                               row['DIST']):\n",
    "                # because sometimes salt bridges makes two concurrent connections so it is possible that we have one distance\n",
    "                # for two amino acids or ligand atoms! Encoding by atom is crazy fun\n",
    "                for dist, aa_atm_coord, frag_lig_atm_coord in zip (dist_list, aa_atm_coord_list, \n",
    "                                                                                 frag_lig_atm_coord_list):\n",
    "                    temp_plifs_prot[tuple(aa_atm_coord)]=[interaction,dist]\n",
    "                    temp_plifs_frag[tuple(frag_lig_atm_coord)]=[interaction,dist]\n",
    "\n",
    "\n",
    "            pdb = next(pybel.readfile('pdb',os.path.join(path,'ATOM_' + pdb_id + '.pdb')))\n",
    "            ligand = next(pybel.readfile('pdb',os.path.join(path, pdb_id + f'_{str(idx)}'+'.pdb')))\n",
    "            single_pdb_frags.append((pdb,ligand,temp_plifs_prot,temp_plifs_frag))  \n",
    "            \n",
    "        grid=np.zeros((full_batch,200,200,200,features_shape),dtype=np.float32)\n",
    "        \n",
    "        for idx, mols in enumerate(single_pdb_frags):\n",
    "            \n",
    "            print(\"idx\", idx)\n",
    "            coords1, features1 = Feature.get_features(mols[0],mols[2],1)\n",
    "            coords2, features2 = Feature.get_features(mols[1],mols[3],0)\n",
    "\n",
    "            # get the center point of protein\n",
    "            center=(np.max(coords2,axis=0)+np.min(coords2,axis=0))/2\n",
    "            coords=np.concatenate([coords1,coords2],axis = 0)\n",
    "            features=np.concatenate([features1,features2],axis = 0)\n",
    "            assert len(coords) == len(features)\n",
    "            # zero the coordinates \n",
    "            coords = coords-center\n",
    "            grid=Feature.grid(grid,coords,features,idx, rotation_bool=True)\n",
    "        \n",
    "        if train_grids is None:\n",
    "            train_grids = grid\n",
    "        else:\n",
    "            train_grids = np.concatenate([train_grids,grid],axis = 0)\n",
    "        print(train_grids.shape)\n",
    "        \n",
    "        raw=pdb_id\n",
    "        path = os.getcwd()\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", filePath)\n",
    "                \n",
    "        os.chdir(p_directory)\n",
    "        \n",
    "    \n",
    "    with open('train_grids.pkl','wb') as f:\n",
    "        pickle.dump(train_grids, f)\n",
    "\n",
    "    # Second testing grids: \n",
    "    test_label=[]\n",
    "    \n",
    "    for _ , row in test_df.iterrows():\n",
    "        \n",
    "        pdb_id = row['PDB_code']\n",
    "        print('pdb_id', pdb_id)\n",
    "        \n",
    "        os.chdir(f'general_refined_set/{pdb_id}')\n",
    "        \n",
    "        raw=pdb_id\n",
    "        path = os.getcwd()\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", filePath)\n",
    "                \n",
    "        df_plifSpecs = PLIF(PDB = f'{pdb_id}.pdb').fragment_and_plif()\n",
    "        \n",
    "        test_label.extend([row['Kd/Ki']])\n",
    "        \n",
    "        single_pdb_frags = []\n",
    "        for idx, row in df_plifSpecs.iterrows():\n",
    "    \n",
    "            temp_plifs_prot={}\n",
    "            temp_plifs_frag={}\n",
    "            ## do something with fragment_idx . i.e. open the pdb and do your shit with encoding\\\n",
    "            for aa_atm_coord_list, frag_lig_atm_coord_list, interaction, dist_list in zip (row['AA_COORDS'], \n",
    "                                                                                               row['FRAGMENT_ATOMS_COORDS'],\n",
    "                                                                                               row['INTERACTION_TYPE'],\n",
    "                                                                                               row['DIST']):\n",
    "                # because sometimes salt bridges makes two concurrent connections so it is possible that we have one distance\n",
    "                # for two amino acids or ligand atoms! Encoding by atom is crazy fun\n",
    "                for dist, aa_atm_coord, frag_lig_atm_coord in zip (dist_list, aa_atm_coord_list, \n",
    "                                                                                 frag_lig_atm_coord_list):\n",
    "                    temp_plifs_prot[tuple(aa_atm_coord)]=[interaction,dist]\n",
    "                    temp_plifs_frag[tuple(frag_lig_atm_coord)]=[interaction,dist]\n",
    "\n",
    "\n",
    "            pdb = next(pybel.readfile('pdb',os.path.join(path,'ATOM_' + pdb_id + '.pdb')))\n",
    "            ligand = next(pybel.readfile('pdb',os.path.join(path, pdb_id + f'_{str(idx)}'+'.pdb')))\n",
    "            single_pdb_frags.append((pdb,ligand,temp_plifs_prot,temp_plifs_frag))  \n",
    "            \n",
    "        grid=np.zeros((1,200,200,200,features_shape),dtype=np.float32)\n",
    "        \n",
    "        for idx, mols in enumerate(single_pdb_frags):\n",
    "            coords1, features1 = Feature.get_features(mols[0],mols[2],1)\n",
    "            coords2, features2 = Feature.get_features(mols[1],mols[3],0)\n",
    "\n",
    "            # get the center point of protein\n",
    "            center=(np.max(coords2,axis=0)+np.min(coords2,axis=0))/2\n",
    "            coords=np.concatenate([coords1,coords2],axis = 0)\n",
    "            features=np.concatenate([features1,features2],axis = 0)\n",
    "            assert len(coords) == len(features)\n",
    "            # zero the coordinates \n",
    "            coords = coords-center\n",
    "            grid=Feature.grid(grid,coords,features,idx, rotation_bool=False)\n",
    "        \n",
    "        if test_grids is None:\n",
    "            test_grids = grid\n",
    "        else:\n",
    "            test_grids = np.concatenate([test_grids,grid],axis = 0)\n",
    "        print(test_grids.shape)\n",
    "        \n",
    "        raw=pdb_id\n",
    "        path = os.getcwd()\n",
    "        fileList = []\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "        fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "        for filePath in fileList:\n",
    "            try:\n",
    "                os.remove(filePath)\n",
    "            except:\n",
    "                print(\"Error while deleting file : \", filePath)\n",
    "                \n",
    "        os.chdir(p_directory)\n",
    "        \n",
    "    \n",
    "    with open('test_grids.pkl','wb') as f:\n",
    "        pickle.dump(test_grids, f)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb='4eqf_protein.pdb'\n",
    "\n",
    "ions=['CL','MG','ZN','MN','CA']\n",
    "\n",
    "with open(pdb) as f1, open(f\"HOH_{pdb.split('.')[0].split('_')[0]}.pdb\", 'w') as f2:\n",
    "    for line in f1:\n",
    "        if ('HETATM' in line) and any(ion in line for ion in ions):\n",
    "            f2.write(line)\n",
    "                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99684cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plifSpecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plif_specs=list(range(55,64))\n",
    "        #C and N atoms can be hybridized in three ways and S atom can be hybridized in two ways here. \n",
    "        #Hydrogen atom is also considered for feature extraction. I think phosphor atom has 3 or 5 as hyb states but \n",
    "        # in biological system its usually the same recurrent phosphate even in most small molecules so safe to assume one\n",
    "        # hybridization state for this purpose. \n",
    "atom_types = [1,(6,1),(6,2),(6,3),(7,1),(7,2),(7,3),8,15,(16,2),(16,3),\n",
    "              34,9,17,35,53,11,12,13,14,5,19,20,25,29,28,30]+plif_specs\n",
    "\n",
    "len(atom_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ae390",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abc05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plifSpecs['AA_COORDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1302c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLIF:\n",
    "    def __init__(self, PDB: str, MOL_SPLIT_START: int = 70, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(PLIF,self).__init__()\n",
    "        \n",
    "        self.MOL_SPLIT_START=MOL_SPLIT_START\n",
    "        self.pdb=PDB\n",
    "        self.records=['ATOM']\n",
    "        self.values=['HOH','CL','MG','ZN','MN','CA']\n",
    "        self.interaction_slices={\"hydrophobic\":[0,1,6,7,8,9,10],\n",
    "            \"hbond\":[0,1,7,11,13,15,16],\n",
    "            \"waterbridge\":[0,1,[6,7],11,13,16,17],\n",
    "            \"saltbridge\":[0,1,7,10,3,11,12],\n",
    "            \"pistacking\":[0,1,7,11,6,12,13],\n",
    "            \"pication\":[0,1,7,11,3,12,13],\n",
    "            \"halogen\":[0,1,7,10,12,14,15],\n",
    "            \"metal\":[0,1,11,8,6,17,16]} \n",
    "\n",
    "        self.column_names = ['RESNR', 'RESTYPE', 'DIST', 'LIG_IDX','PROT_IDX','FRAGMENT_ATOMS_COORDS', 'AA_COORDS']\n",
    "        self.path = os.getcwd()\n",
    "\n",
    "\n",
    "    def okToBreak(self, bond):\n",
    "        \"\"\"\n",
    "        Here we apply a bunch of rules to judge if the bond is OK to break.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        bond :\n",
    "            RDkit MOL object\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Boolean :\n",
    "            OK or not to break.\n",
    "        \"\"\"\n",
    "        # See if the bond is in Ring (don't break that)\n",
    "        if bond.IsInRing():\n",
    "            return False\n",
    "        # We OK only single bonds to break\n",
    "        if bond.GetBondType() != Chem.rdchem.BondType.SINGLE:\n",
    "            return False\n",
    "\n",
    "        # Get the beginning atom of the bond\n",
    "        begin_atom = bond.GetBeginAtom()\n",
    "        # Get the ending atom of the bond\n",
    "        end_atom = bond.GetEndAtom()\n",
    "        # What kind of neighbors does these end and begenning atoms have? We need a family of no less than 5!\n",
    "        neighbor_end=list(end_atom.GetNeighbors())\n",
    "        neighbor_begin=list(begin_atom.GetNeighbors())\n",
    "        if (len(neighbor_end) + len(neighbor_begin)) <5:\n",
    "            return False\n",
    "        #for atm in neighbor_end:\n",
    "            #print(atm.GetAtomicNum())\n",
    "        #print(begin_atom.GetAtomicNum(), end_atom.GetAtomicNum(), MOL_SPLIT_START)\n",
    "        \n",
    "        # Now check if end or begenning atoms are in ring (we dont wanna bother those)\n",
    "        if not(begin_atom.IsInRing() or end_atom.IsInRing()):\n",
    "            return False\n",
    "        elif begin_atom.GetAtomicNum() >= self.MOL_SPLIT_START or \\\n",
    "                end_atom.GetAtomicNum() >= self.MOL_SPLIT_START:\n",
    "            return False\n",
    "        elif end_atom.GetAtomicNum() == 1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def undo_id_label (self, frag, split_id):\n",
    "        # I am trying to restore Hydrogens where the break happened\n",
    "        for i, atom in enumerate(frag.GetAtoms()):\n",
    "            if atom.GetAtomicNum() >= split_id:\n",
    "                atom.SetAtomicNum(1)\n",
    "\n",
    "        return frag\n",
    "\n",
    "    # Divide a molecule into fragments\n",
    "    def split_molecule(self, mol, pdb):\n",
    "\n",
    "        split_id = self.MOL_SPLIT_START\n",
    "\n",
    "        res = []\n",
    "        res_no_id=[]\n",
    "\n",
    "        to_check = [mol]\n",
    "        while len(to_check) > 0:\n",
    "            ms = self.spf(to_check.pop(), split_id)\n",
    "            if len(ms) == 1:\n",
    "                res += ms\n",
    "            else:\n",
    "                to_check += ms\n",
    "                split_id += 1\n",
    "        for frag in res:\n",
    "            res_no_id.append(self.undo_id_label(frag, self.MOL_SPLIT_START))\n",
    "\n",
    "        res_pdb_frags=[]\n",
    "\n",
    "        for idx, frag in enumerate(res_no_id):\n",
    "            w = Chem.PDBWriter(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "            w.write(frag)\n",
    "            w.close()\n",
    "            \n",
    "            unwanted_entries= ['CONECT', 'END']            \n",
    "            with open(f\"tmp_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as oldfile, open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as newfile:\n",
    "                for line in oldfile:\n",
    "                    if not any(unwanted_entry in line for unwanted_entry in unwanted_entries):\n",
    "                        newfile.write(line)\n",
    "\n",
    "                    \n",
    "            data = data2 = \"\"\n",
    "\n",
    "            # Reading data from file1\n",
    "            with open(f\"ATOM_{pdb}.pdb\") as fp:\n",
    "                data = fp.read()\n",
    "\n",
    "            # Reading data from file2\n",
    "\n",
    "            with open(f\"{pdb}_{self.MOL_SPLIT_START+idx}.pdb\") as fp:\n",
    "                data2 = fp.read()\n",
    "            \n",
    "            # Merging 2 files\n",
    "            # To add the data of file2\n",
    "            # from next line\n",
    "            #data += \"\\n\"\n",
    "            data += data2\n",
    "            \n",
    "            with open(f\"HOH_{pdb}.pdb\") as fp:\n",
    "                data3 = fp.read()\n",
    "            data += data3\n",
    "\n",
    "            with open (f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\", 'w') as fp:\n",
    "                fp.write(data)\n",
    "            res_pdb_frags.append(f\"ATOM_{pdb}_{self.MOL_SPLIT_START+idx}.pdb\")\n",
    "        return res_pdb_frags #create_chain(res)\n",
    "\n",
    "\n",
    "    # Function for doing all the nitty gritty splitting work.\n",
    "    # loops over bonds until bonds get exhausted or bonds are ok to break, whichever comes first. If ok to break, then each\n",
    "    # fragment needs to be checked individually again through the loop\n",
    "    def spf(self, mol, split_id):\n",
    "\n",
    "        bonds = mol.GetBonds()\n",
    "        for i in range(len(bonds)):\n",
    "            if self.okToBreak(bonds[i]):\n",
    "                mol = Chem.FragmentOnBonds(mol, [i])\n",
    "                # Dummy atoms are always added last\n",
    "                n_at = mol.GetNumAtoms()\n",
    "                print('Split ID', split_id)\n",
    "                mol.GetAtomWithIdx(n_at-1).SetAtomicNum(split_id)\n",
    "                mol.GetAtomWithIdx(n_at-2).SetAtomicNum(split_id)\n",
    "                return Chem.rdmolops.GetMolFrags(mol, asMols=True)\n",
    "\n",
    "        # If the molecule could not been split, return original molecule\n",
    "        return [mol]\n",
    "    #get_fragments(fragment_mols)\n",
    "\n",
    "    def retreive_plip_interactions(self, pdb_file):\n",
    "        \"\"\"\n",
    "        Retreives the interactions from PLIP.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pdb_file :\n",
    "            The PDB file of the complex. \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict :\n",
    "            A dictionary of the binding sites and the interactions.\n",
    "        \"\"\"\n",
    "        protlig = PDBComplex()   #instantiate the loader from PLIP\n",
    "        protlig.load_pdb(pdb_file)   # load the pdb file\n",
    "        for ligand in protlig.ligands:\n",
    "            protlig.characterize_complex(ligand)   # find ligands and analyze interactions\n",
    "        sites = {}\n",
    "        # loop over binding sites\n",
    "        for key, site in sorted(protlig.interaction_sets.items()):\n",
    "            binding_site = BindingSiteReport(site)   # collect data about interactions\n",
    "            # tuples of *_features and *_info will be converted to pandas DataFrame\n",
    "            keys = (\n",
    "                \"hydrophobic\",\n",
    "                \"hbond\",\n",
    "                \"waterbridge\",\n",
    "                \"saltbridge\",\n",
    "                \"pistacking\",\n",
    "                \"pication\",\n",
    "                \"halogen\",\n",
    "                \"metal\"\n",
    "            )\n",
    "        # interactions is a dictionary which contains relevant information for each\n",
    "        # of the possible interactions: hydrophobic, hbond, etc. in the considered\n",
    "        # binding site. Each interaction contains a list with \n",
    "        # 1. the features of that interaction, e.g. for hydrophobic:\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "        # 2. information for each of these features, e.g. for hydrophobic\n",
    "        # ('RES_number', 'RES_type', ..., 'LIG_coord', 'PROT_coord')\n",
    "\n",
    "            interactions = {\n",
    "                k: [getattr(binding_site, k + \"_features\")] + getattr(binding_site, k + \"_info\")\n",
    "                for k in keys\n",
    "            }\n",
    "            sites[key] = interactions\n",
    "        return sites\n",
    "\n",
    "    def get_coords_prot(self, RESNR):\n",
    "        ppdb = PandasPdb()\n",
    "        ppdb.read_pdb(f\"{self.pdb.split('.')[0]}_protein.pdb\")\n",
    "        only_protein=ppdb.df['ATOM']\n",
    "        resnr_coords=[]\n",
    "        for i in RESNR:\n",
    "            resnr_coords.append(list(only_protein[only_protein['atom_number']==int(i)][['x_coord', 'y_coord', 'z_coord']].values[0]))\n",
    "        return resnr_coords\n",
    "    \n",
    "    def interaction_df(self, split):\n",
    "\n",
    "        all_interactions_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "        # We create the dictionary for the complex of interest:\n",
    "        for idx, s in enumerate(split):\n",
    "\n",
    "            pdb_id=s.split('.')[0]\n",
    "            raw=pdb_id.split('_')[1]\n",
    "            idx_frag=int(pdb_id.split('_')[2])\n",
    "            interactions_by_site = self.retreive_plip_interactions(f\"{pdb_id}.pdb\")\n",
    "\n",
    "            # Let’s see how many binding sites are detected:\n",
    "\n",
    "    #         print(\n",
    "    #             f\"Number of binding sites detected in {pdb_id} : \"\n",
    "    #             f\"{len(interactions_by_site)}\\n\"\n",
    "    #             f\"with {interactions_by_site.keys()}\"\n",
    "    #         )\n",
    "            # In this case, the first binding site containing ligand 03P will be further investigated.\n",
    "            index_of_selected_site = 0\n",
    "            selected_site = list(interactions_by_site.keys())[index_of_selected_site]\n",
    "            #print(selected_site)\n",
    "\n",
    "\n",
    "            valid_types = [\n",
    "                    \"hydrophobic\",\n",
    "                    \"hbond\",\n",
    "                    \"waterbridge\",\n",
    "                    \"saltbridge\",\n",
    "                    \"pistacking\",\n",
    "                    \"pication\",\n",
    "                    \"halogen\",\n",
    "                    \"metal\",\n",
    "                ]\n",
    "\n",
    "            for _type in valid_types:\n",
    "                output_df=self.create_df_from_binding_site(raw, interactions_by_site[selected_site], idx+self.MOL_SPLIT_START, selected_site,\n",
    "                                                      interactions_by_site,\n",
    "                                                      interaction_type=_type)\n",
    "                all_interactions_df=all_interactions_df.append(output_df)\n",
    "        all_interactions_df = all_interactions_df[all_interactions_df['RESNR'].notna()]\n",
    "        all_interactions_df.to_csv(f\"{self.path}/results_plifs/{raw}_plifs_and_properties.csv\", index=False)\n",
    "        return all_interactions_df\n",
    "\n",
    "\n",
    "    # We can construct a pandas.DataFrame for a binding site and particular interaction type.\n",
    "\n",
    "    def create_df_from_binding_site(self, raw, selected_site_interactions, fragment_idx, selected_site, \n",
    "                                    interactions_by_site, interaction_type=\"hbond\"):\n",
    "        \"\"\"\n",
    "        Creates a data frame from a binding site and interaction type.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        selected_site_interactions : dict\n",
    "            Precalculated interactions from PLIP for the selected site\n",
    "        interaction_type : str\n",
    "            The interaction type of interest (default set to hydrogen bonding).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame :\n",
    "            DataFrame with information retreived from PLIP.\n",
    "        \"\"\"\n",
    "        # check if interaction type is valid:\n",
    "        valid_types = [\n",
    "            \"hydrophobic\",\n",
    "            \"hbond\",\n",
    "            \"waterbridge\",\n",
    "            \"saltbridge\",\n",
    "            \"pistacking\",\n",
    "            \"pication\",\n",
    "            \"halogen\",\n",
    "            \"metal\",\n",
    "        ]\n",
    "\n",
    "\n",
    "        if interaction_type not in valid_types:\n",
    "            print(\"!!! Wrong interaction type specified. Hbond is chosen by default !!! \\n\")\n",
    "            interaction_type = \"hbond\"\n",
    "\n",
    "        def interaction_values(n):\n",
    "            try:\n",
    "                interactions=interactions_by_site[selected_site][interaction_type]\n",
    "                if type(n) is list:\n",
    "                    return [interactions[1:][x][i] for x in \n",
    "                        range(len(interactions[1:])) for i in n]\n",
    "                else:\n",
    "                    return [interactions[1:][x][n] for x in \n",
    "                        range(len(interactions[1:]))]\n",
    "            except Exception:\n",
    "                return None\n",
    "            \n",
    "        if interactions_by_site[selected_site][interaction_type][1:]:\n",
    "            #print(list(map(interaction_values, self.interaction_slices[interaction_type])), self.column_names)\n",
    "            selected_feats=list(map(interaction_values, self.interaction_slices[interaction_type]))\n",
    "            #print(selected_feats)\n",
    "            try: \n",
    "                if int(selected_feats[4])>int(selected_feats[3]):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3]  \n",
    "            except: \n",
    "                if int(any(selected_feats[4]))>int(any(selected_feats[3])):\n",
    "                    selected_feats[3], selected_feats[4] = selected_feats[4], selected_feats[3] \n",
    "            df = pd.DataFrame(\n",
    "                # data is stored AFTER the columns names\n",
    "                [selected_feats],\n",
    "                # column names are always the first element - we skipped that in the above - we are gonna use that for naming the df\n",
    "                columns = self.column_names\n",
    "            )\n",
    "\n",
    "            df[\"INTERACTION_TYPE\"]=interaction_type\n",
    "            \n",
    "            try:\n",
    "                checked_coords=self.get_coords_prot(selected_feats[4][0].split(',') if ',' in selected_feats[4][0] \\\n",
    "                                                                   else selected_feats[4])\n",
    "            except:\n",
    "                checked_coords=selected_feats[6]\n",
    "                \n",
    "            df[\"AA_COORDS\"]=[checked_coords]\n",
    "                #[self.get_coords_prot(selected_feats[4].split(','))]\n",
    "            df[\"FRAGMENT_ATOMS_COORDS\"]=[selected_feats[5]]\n",
    "                            #[self.get_coords_lig(selected_feats[3].split(','))]    \n",
    "            df['FRAGMENT_ID']=fragment_idx\n",
    "\n",
    "            # ideally we would like to exclude waters from further processing. Threrfore let us reduce any waterbridge \n",
    "            # interaction to the eucladean distance in order to omit water\n",
    "            \n",
    "            if interaction_type == \"waterbridge\":\n",
    "                df['DIST']=[[np.linalg.norm(x) for x in df['DIST'].to_numpy()]]\n",
    "                \n",
    "            # also deal with one distance value and two coords, this is common in saltbridge interactions:\n",
    "            if len(checked_coords) == len(selected_feats[2])*2:\n",
    "                df['DIST']=[selected_feats[2] + selected_feats[2]]\n",
    "                \n",
    "        else:\n",
    "\n",
    "            df= pd.DataFrame({'RESNR':[None], 'RESTYPE':[None], 'DIST':[None], 'LIG_IDX':[None],'PROT_IDX':[None],\n",
    "                        'INTERACTION_TYPE':[interaction_type], \"AA_COORDS\": [None], \"FRAGMENT_ATOMS_COORDS\":[None],\n",
    "                              'FRAGMENT_ID':[str(fragment_idx)]})\n",
    "\n",
    "\n",
    "\n",
    "        return df\n",
    "    def pdb_2_sdf(self, pdb):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"pdb\", \"sdf\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, pdb)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "\n",
    "\n",
    "        obConversion.WriteFile(mol, f\"{pdb.split('.')[0]}.sdf\")\n",
    "        return f\"{pdb.split('.')[0]}.sdf\"\n",
    "    \n",
    "    def sdf_2_pdb(self, sdf):\n",
    "        obConversion = openbabel.OBConversion()\n",
    "        obConversion.SetInAndOutFormats(\"sdf\", \"pdb\")\n",
    "        mol = openbabel.OBMol()\n",
    "        obConversion.ReadFile(mol, sdf)   # Open Babel will uncompress automatically\n",
    "\n",
    "        mol.AddHydrogens()\n",
    "        obConversion.WriteFile(mol, f\"{sdf.split('.')[0]}.pdb\")\n",
    "        return f\"HETATM_{sdf.split('.')[0]}.pdb\"\n",
    "\n",
    "    def save_bpdb(self, pdb,ppdb, record):  \n",
    "        ppdb.to_pdb(path=f\"{record}_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                    records=[record],\n",
    "                    gz=False, \n",
    "                    append_newline=True)\n",
    "\n",
    "    def get_HOH_pdb(self, pdb):\n",
    "        ppdb = PandasPdb() \n",
    "        ppdb.read_pdb(pdb) \n",
    "        ppdb.df['HETATM']=ppdb.df['HETATM'].loc[ppdb.df['HETATM']['residue_name'].isin(self.values)]\n",
    "        ppdb.to_pdb(path=f\"HOH_{pdb.split('.')[0].split('_')[0]}.pdb\",\n",
    "                records=['HETATM'],\n",
    "                gz=False, \n",
    "                append_newline=True)\n",
    "\n",
    "    def keep_relevant_hetatm(self, pdb):\n",
    "        with open(pdb) as f1, open(f\"ATOM_{pdb.split('.')[0].split('_')[0]}.pdb\", 'w') as f2:\n",
    "            for line in f1:\n",
    "                if 'ATOM' in line:\n",
    "                    f2.write(line)\n",
    "                    \n",
    "        self.get_HOH_pdb(pdb)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def fragment_and_plif(self):\n",
    "        path = os.getcwd()\n",
    "        if not os.path.exists('results_plifs'):\n",
    "            os.mkdir(f'{path}/results_plifs')\n",
    "         \n",
    "        raw=str(self.pdb).split('.')[0]\n",
    "        self.keep_relevant_hetatm(f'{raw}_protein.pdb')\n",
    "        self.sdf_2_pdb(f'{raw}_ligand.sdf')\n",
    "        fragment_mols = Chem.SDMolSupplier(str(f'{raw}_ligand.sdf'), removeHs=True, sanitize=False)\n",
    "        try: fragment_mols = Chem.RemoveHs(fragment_mols[0])\n",
    "        except Exception: fragment_mols = AllChem.MolFromPDBFile(f'{raw}_ligand.pdb')\n",
    "        try: output_df = self.interaction_df(self.split_molecule(fragment_mols,raw))\n",
    "        except: output_df = self.interaction_df(self.split_molecule( Chem.MolFromMol2File(f'{raw}_ligand.mol2', sanitize=True, removeHs=True),raw))\n",
    "        \n",
    "\n",
    "        os.chdir(f'{path}')\n",
    "        \n",
    "        return output_df.groupby('FRAGMENT_ID')['AA_COORDS', 'FRAGMENT_ATOMS_COORDS','INTERACTION_TYPE','DIST'].agg(list)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    p_directory = os.getcwd()\n",
    "    \n",
    "    pdb_id = '5etb'\n",
    "    os.chdir(f'/groups/cherkasvgrp/share/progressive_docking/hmslati/plif_cnn/general_refined_set/{pdb_id}')\n",
    "\n",
    "    df_plifSpecs = PLIF(PDB = f'{pdb_id}.pdb').fragment_and_plif()\n",
    "    \n",
    "    os.chdir('/groups/cherkasvgrp/share/progressive_docking/hmslati/plif_cnn/general_refined_set/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "os.chdir('/groups/cherkasvgrp/share/progressive_docking/hmslati/plif_cnn/general_refined_set/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "raw='5etb'\n",
    "fileList = []\n",
    "fileList.extend(glob.glob(f'{path}/{raw}_7*pdb'))\n",
    "fileList.extend(glob.glob(f'{path}/{raw}_8*pdb'))\n",
    "fileList.extend(glob.glob(f'{path}/{raw}_9*pdb'))\n",
    "fileList.extend(glob.glob(f'{path}/*_{raw}*pdb'))\n",
    "fileList.extend(glob.glob(f'{path}/*_{raw}*sdf'))\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except:\n",
    "        print(\"Error while deleting file : \", filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plifSpecs['AA_COORDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 45次实验分别进行10倍交叉验证，取平均\n",
    "\n",
    "#Converts the protein-ligand complexes into 4D tensor. \n",
    "class Feature_extractor():\n",
    "    def __init__(self):\n",
    "        self.atom_codes = {}\n",
    "        #'others' includs metal atoms and B atom. There are no B atoms on training and test sets. \n",
    "        # 55 to 65 will be reserved to PLIF features as follows:\n",
    "        # 55: hydrophobic\n",
    "        # 56: hbond\n",
    "        # 57: waterbridge\n",
    "        # 58: saltbridge\n",
    "        # 59: pistacking\n",
    "        # 60: pication\n",
    "        # 61: halogen\n",
    "        # 62: metal\n",
    "        # 63: Distances \n",
    "        # 64: SASA ATOM\n",
    "        # 65: SASA AA\n",
    "        \n",
    "        # others = ([3,4,5,11,12,13]+list(range(19,32))+list(range(37,51))+list(range(55,84)))\n",
    "        plif_specs=list(range(55,66))\n",
    "        #C and N atoms can be hybridized in three ways and S atom can be hybridized in two ways here. \n",
    "        #Hydrogen atom is also considered for feature extraction. I think phosphor atom has 3 or 5 as hyb states but \n",
    "        # in biological system its usually the same recurrent phosphate even in most small molecules so safe to assume one\n",
    "        # hybridization state for this purpose. \n",
    "        atom_types = [1,(6,1),(6,2),(6,3),(7,1),(7,2),(7,3),8,15,(16,2),(16,3),\n",
    "                      34,9,17,35,53,11,12,13,14,5,19,20,25,29,28,30]+plif_specs\n",
    "      \n",
    "        for i, j in enumerate(atom_types):\n",
    "            if type(j) is list:\n",
    "                for k in j:\n",
    "                    self.atom_codes[k] = i\n",
    "                \n",
    "            else:\n",
    "                self.atom_codes[j] = i              \n",
    "        \n",
    "        self.sum_atom_types = len(atom_types)\n",
    "        \n",
    "    #Onehot encoding of each atom. The atoms in protein or ligand are treated separately.\n",
    "    def encode(self, atomic_num, orig_coords, plifs, molprotein):\n",
    "        encoding = np.zeros(self.sum_atom_types*2)\n",
    "        if molprotein == 1:\n",
    "            encoding[self.atom_codes[atomic_num]] = 1.0\n",
    "            for coord, plif_feats in plifs.items():\n",
    "                if [round(item) for item in coord] == [round(item) for item in orig_coords]:\n",
    "                    encoding[self.atom_codes[55]] = 1.0 if plifs[coord][0] == 'hydrophobic' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[56]] = 1.0 if plifs[coord][0] == 'hbond' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[57]] = 1.0 if plifs[coord][0] == 'waterbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[58]] = 1.0 if plifs[coord][0] == 'saltbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[59]] = 1.0 if plifs[coord][0] == 'pistacking' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[60]] = 1.0 if plifs[coord][0] == 'pication' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[61]] = 1.0 if plifs[coord][0] == 'halogen' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.atom_codes[62]] = 1.0 if plifs[coord][0] == 'metal' \\\n",
    "                    else 0.0\n",
    "                    \n",
    "                    encoding[self.atom_codes[63]] = plifs[coord][1]\n",
    "                    encoding[self.atom_codes[64]] = plifs[coord][2]\n",
    "                    encoding[self.atom_codes[65]] = plifs[coord][3]\n",
    "                \n",
    "        else:\n",
    "            encoding[self.sum_atom_types+self.atom_codes[atomic_num]] = 1.0\n",
    "            for coord, plif_feats in plifs.items():\n",
    "                if [round(item) for item in coord] == [round(item) for item in orig_coords]:\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[55]] = 1.0 if plifs[coord][0] == 'hydrophobic' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[56]] = 1.0 if plifs[coord][0] == 'hbond' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[57]] = 1.0 if plifs[coord][0] == 'waterbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[58]] = 1.0 if plifs[coord][0] == 'saltbridge' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[59]] = 1.0 if plifs[coord][0] == 'pistacking' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[60]] = 1.0 if plifs[coord][0] == 'pication' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[61]] = 1.0 if plifs[coord][0] == 'halogen' \\\n",
    "                    else 0.0\n",
    "                    encoding[self.sum_atom_types+self.atom_codes[62]] = 1.0 if plifs[coord][0] == 'metal' \\\n",
    "                    else 0.0\n",
    "                    \n",
    "                    encoding[self.sum_atom_types+self.atom_codes[63]] = plifs[coord][1]\n",
    "                    \n",
    "        \n",
    "        return encoding\n",
    "    \n",
    "    #Get atom coords and atom features from the complexes.   \n",
    "    def get_features(self, molecule, plifs, molprotein):\n",
    "        coords = []\n",
    "        features = []\n",
    "            \n",
    "        for atom in molecule:\n",
    "            coords.append(atom.coords)\n",
    "            if atom.atomicnum in [6,7,16]:\n",
    "                atomicnum = (atom.atomicnum,atom.hyb)\n",
    "                features.append(self.encode(atomicnum,atom.coords,plifs,molprotein))\n",
    "            else:\n",
    "                features.append(self.encode(atom.atomicnum,atom.coords,plifs,molprotein))\n",
    "        \n",
    "        coords = np.array(coords, dtype=np.float32)\n",
    "        features = np.array(features, dtype=np.float32)\n",
    "\n",
    "        return coords, features\n",
    "     \n",
    "    #Define the rotation matrixs of 3D stuctures.\n",
    "    def rotation_matrix(self, t, roller):\n",
    "        if roller==0:\n",
    "            return np.array([[1,0,0],[0,np.cos(t),np.sin(t)],[0,-np.sin(t),np.cos(t)]])\n",
    "        elif roller==1:\n",
    "            return np.array([[np.cos(t),0,-np.sin(t)],[0,1,0],[np.sin(t),0,np.cos(t)]])\n",
    "        elif roller==2:\n",
    "            return np.array([[np.cos(t),np.sin(t),0],[-np.sin(t),np.cos(t),0],[0,0,1]])\n",
    "\n",
    "    #Generate 3d grid or 4d tensor. Each grid represents a voxel. Each voxel represents the atom in it by onehot encoding of atomic type.\n",
    "    #Each complex in train set is rotated 9 times for data amplification.\n",
    "    #The complexes in core set are not rotated. \n",
    "    #The default resolution is 20*20*20.\n",
    "    def grid(self,grid, coords, features, frag_idx, resolution=1.0, max_dist=10.0,  rotation_bool=True, max_frag=10, rotations=9):\n",
    "        assert coords.shape[1] == 3\n",
    "        assert coords.shape[0] == features.shape[0]  \n",
    "\n",
    "        slider=frag_idx*20\n",
    "\n",
    "        x=y=z=np.array(range(-10,10),dtype=np.float32)+0.5\n",
    "        u=0\n",
    "        for i in range(len(coords)):\n",
    "            coord=coords[i]\n",
    "            # add/subtract 10 from the center\n",
    "            tmpx=abs(coord[0]-x)\n",
    "            tmpy=abs(coord[1]-y)\n",
    "            tmpz=abs(coord[2]-z)\n",
    "\n",
    "            if np.max(tmpx)<=19.5 and np.max(tmpy)<=19.5 and np.max(tmpz) <=19.5:\n",
    "                u+=1\n",
    "                # get the position of the closest point to coordinate which is found inside the grid\n",
    "                # append the features unto that slice\n",
    "                grid[0,slider+np.argmin(tmpx),slider+np.argmin(tmpy),slider+np.argmin(tmpz)] += features[i]\n",
    "                \n",
    "        if rotation_bool:\n",
    "            for rotation_idx in range(rotations):\n",
    "                theta = random.uniform(np.pi/18,np.pi/2)\n",
    "                roller = random.randrange(3)\n",
    "                coords = np.dot(coords, self.rotation_matrix(theta,roller))\n",
    "                for i in range(len(coords)):\n",
    "                    coord=coords[i]\n",
    "                    tmpx=abs(coord[0]-x)\n",
    "                    tmpy=abs(coord[1]-y)\n",
    "                    tmpz=abs(coord[2]-z)\n",
    "                    if np.max(tmpx)<=19.5 and np.max(tmpy)<=19.5 and np.max(tmpz) <=19.5:\n",
    "                        grid[rotation_idx+1,slider+np.argmin(tmpx),slider+np.argmin(tmpy),slider+np.argmin(tmpz)] += features[i]\n",
    "\n",
    "        return grid\n",
    "\n",
    "Feature = Feature_extractor()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Feature engineering of training set.\n",
    "train_complexes = []\n",
    "directory = os.getcwd()\n",
    "#for frag in range(70,77):\n",
    "pdb_id = '1xk5'\n",
    "\n",
    "for idx, row in df_plifSpecs.iterrows():\n",
    "    \n",
    "    temp_plifs_prot={}\n",
    "    temp_plifs_frag={}\n",
    "    ## do something with fragment_idx . i.e. open the pdb and do your shit with encoding\\\n",
    "    for aa_atm_coord_list, frag_lig_atm_coord_list, interaction, dist_list, aa_atm_asa_list, aa_asa_list in zip (row['AA_COORDS'], \n",
    "                                                                                       row['FRAGMENT_ATOMS_COORDS'],\n",
    "                                                                                       row['INTERACTION_TYPE'],\n",
    "                                                                                       row['DIST'],\n",
    "                                                                                       row['ATOM_SASA'],\n",
    "                                                                                       row['AA_SASA']):\n",
    "        # because sometimes salt bridges makes two concurrent connections so it is possible that we have one distance\n",
    "        # for two amino acids or ligand atoms! Encoding by atom is crazy fun\n",
    "        for dist, aa_atm_coord, frag_lig_atm_coord, aa_atm_asa, aa_asa in zip (dist_list, aa_atm_coord_list, \n",
    "                                                                         frag_lig_atm_coord_list,\n",
    "                                                                        aa_atm_asa_list,\n",
    "                                                                        aa_asa_list):\n",
    "            temp_plifs_prot[tuple(aa_atm_coord)]=[interaction,dist,aa_atm_asa,aa_asa]\n",
    "            temp_plifs_frag[tuple(frag_lig_atm_coord)]=[interaction,dist,aa_atm_asa,aa_asa]\n",
    "\n",
    "    \n",
    "    pdb = next(pybel.readfile('pdb',os.path.join(directory,'ATOM_' + pdb_id + '.pdb')))\n",
    "    ligand = next(pybel.readfile('pdb',os.path.join(directory, pdb_id + f'_{str(idx)}'+'.pdb')))\n",
    "    train_complexes.append((pdb,ligand,temp_plifs_prot,temp_plifs_frag))   \n",
    "    \n",
    "#ligand = next(pybel.readfile('pdb',os.path.join(directory,pdb_id + '_' + str(frag) + '.pdb')))\n",
    "\n",
    "train_grids=None\n",
    "rotations=9\n",
    "full_batch=10\n",
    "features_shape=76\n",
    "\n",
    "grid=np.zeros((full_batch,200,200,200,features_shape),dtype=np.float32)\n",
    "for idx, mols in enumerate(train_complexes):\n",
    "    coords1, features1 = Feature.get_features(mols[0],mols[2],1)\n",
    "    coords2, features2 = Feature.get_features(mols[1],mols[3],0)\n",
    "\n",
    "    # get the center point of protein\n",
    "    center=(np.max(coords2,axis=0)+np.min(coords2,axis=0))/2\n",
    "    coords=np.concatenate([coords1,coords2],axis = 0)\n",
    "    features=np.concatenate([features1,features2],axis = 0)\n",
    "    assert len(coords) == len(features)\n",
    "    # zero the coordinates \n",
    "    coords = coords-center\n",
    "    print(grid.shape)\n",
    "    grid=Feature.grid(grid,coords,features,idx, rotation_bool=True)\n",
    "if train_grids is None:\n",
    "    train_grids = grid\n",
    "else:\n",
    "    train_grids = np.concatenate([train_grids,grid],axis = 0)\n",
    "print('hi')\n",
    "with open('train_grids.pkl','wb') as f:\n",
    "    pickle.dump(train_grids, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
